[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Code Club!",
    "section": "",
    "text": "Code Club aims to support everyone at SCW in developing technical and analytical skills through interpretive dance code. We believe these skills are indispensable to the NHS today and in the future, enabling the delivery of high-quality insights through data science and advanced analytics, and the automation of day-to-day tasks with programming. We want to foster an environment that welcomes everybody, sparks ideas, and nurtures collaboration.\nThe Code Club syllabus has been designed to help people with little to no coding experience develop their skills in Python and extend their analytical skills through code. Sessions will be an hour long and held once per fortnight at 2:00 PM on Thursdays. To get an idea of what we will be covering and see if it is right for you, go to the Schedule page. We would love for you to join us!"
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/index.html",
    "href": "sessions/02-jupyter_notebooks/index.html",
    "title": "Jupyter Notebooks",
    "section": "",
    "text": "This is the second session following Code Club‚Äôs relaunch. The focus is introducing jupyter notebooks and explaining to users how to get started with a new project and briefly introducing some key concepts.\nWe are also planning some time for Q&A following the first session.",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "2. Jupyter Notebooks"
    ]
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/index.html#session-slides",
    "href": "sessions/02-jupyter_notebooks/index.html#session-slides",
    "title": "Jupyter Notebooks",
    "section": "Session Slides",
    "text": "Session Slides\nUse the left ‚¨ÖÔ∏è and right ‚û°Ô∏è arrow keys to navigate through the slides below. To view in a separate tab/window, follow this link.",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "2. Jupyter Notebooks"
    ]
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/index.html#the-tools-you-will-need",
    "href": "sessions/02-jupyter_notebooks/index.html#the-tools-you-will-need",
    "title": "Jupyter Notebooks",
    "section": "The Tools You Will Need",
    "text": "The Tools You Will Need\nThough Jupyter notebooks can be used with a variety of coding languages and in different settings the key tools used in this session are:\n\nLanguage: Python\nDependency Management & Virtual Environments: uv\nVersion Control: Git, GitHub Desktop\nIDE: VS Code/Jupyter Notebooks (or your preferred IDE)\n\nYou can install all the tools you‚Äôll need by running the following one-liner run in PowerShell:\nwinget install astral-sh.uv Microsoft.VisualStudioCode github-desktop\nYou can find more information on these topics in the Python Onboarding session",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "2. Jupyter Notebooks"
    ]
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/index.html#project-setup",
    "href": "sessions/02-jupyter_notebooks/index.html#project-setup",
    "title": "Jupyter Notebooks",
    "section": "Project Setup",
    "text": "Project Setup\nOur project set-up will follow the same steps as used in the onboarding session, by using uv to set up a new project folder.\nTo get started we will use PowerShell powershell to open a command prompt, it should open in your C drive (e.g., C:\\Users\\user.name). If it does not, run cd ~, and it should return to your home directory. We recommend the use of a single folder to hold your python projects while learning, because we will be using git version control we will call this ‚ÄúGit‚Äù. we can use the command mkdir code_club to make this folder and then use cd code_club to relocate to this folder1.\nWe will create a new uv project in this directory using the command uv init. The new project will contain everything we need, including a Python installation, a virtual environment, and the necessary project files for tracking and managing any packages installed in the virtual environment. To set up a new project called test-project, use the following command:\nuv init test_project\nHaving created this new directory, navigate to it using cd test_project.\nFor this session you will need to add 3 Python packages, ipykernel2, pandas and seaborn We can use the following command:\nuv add ipykernel pandas seaborn\nWe are going to create a blank notebook in this file by running the command new-item first_notebook.ipynb if you now run ls you will note this file has been created\nYour Python project is now set up, and you are ready to start writing some code. You can open VS Code from your PowerShell window by running code ..\n\nOpening your project in VS Code\nYou could also do this from within VS Code as most IDEs include a terminal interface which will be demonstrated in session.\nFor now launch VS Code and click File &gt; Open Folder.... You‚Äôll want to make sure you select the root level of your project. Once you‚Äôve opened the folder, the file navigation pane in VS Code should display the files that uv has created, as well as the notebook you created: first_notebook.ipynb. Click on this to open it.\nOnce VS Code realises you‚Äôve opened a folder with Python code and a virtual environment, it should do the following:\n\nSuggest you install the Python extension (and, once you‚Äôve created a Jupyter notebook, the Jupyter one) offered by Microsoft - go ahead and do this. If this doesn‚Äôt happen, you can install extensions manually from the Extensions pane on the left-hand side.\nSelect the uv-created .venv as the python Environment we‚Äôre going to use to actually run our code. If this doesn‚Äôt happen, press ctrl-shift-P, type ‚Äúpython environment‚Äù to find the Python - Create Environment... option, hit enter, choose ‚ÄúVenv‚Äù and proceed to ‚ÄúUse Existing‚Äù.\n\nIf VS Code has found the virtual environment, it may pick up the correct kernel. If not you may need to select this manually this can be done by clicking in the top right where you can see Select Kernel (see below)\n\n\n\nClick ‚ÄòSelect Kernel‚Äô\n\n\nWe can then select the appropriate kernel from python environments and looking for\n\n\n\nclick Python Environments\n\n\n\n\n\nclick venv - recommended\n\n\nOnce the kernel is enabled you are ready to start adding cells to your notebook. these can either be code cells which is where you include your program elements or markdown which enable the addition of headings, analysis and commentary.",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "2. Jupyter Notebooks"
    ]
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/index.html#footnotes",
    "href": "sessions/02-jupyter_notebooks/index.html#footnotes",
    "title": "Jupyter Notebooks",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe recommend using the C drive for all Python projects, especially if using version control. Storing projects like these on One Drive will create many unnecessary issues. It can be helpful to use a sub-directory to store projects but is not necessary and is not a requirement for code club‚Ü©Ô∏é\nStrictly speaking, we should install ipykernel as a development dependency (a dependency that is needed for any development but not when the project is put into production). In this case, we would add it by running uv add --dev ipykernel. However, in this case, it is simpler to just add it as a regular dependency, and it doesn‚Äôt harm.‚Ü©Ô∏é",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "2. Jupyter Notebooks"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html",
    "href": "sessions/11-analysing-relationships/index.html",
    "title": "Analysing Penguins Relationships",
    "section": "",
    "text": "This notebook explores relationships in data and the process for analysing relationships, using the TidyTuesday Palmer Penguins dataset. We‚Äôll cover:",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#why-analyse-relationships",
    "href": "sessions/11-analysing-relationships/index.html#why-analyse-relationships",
    "title": "Analysing Penguins Relationships",
    "section": "Why Analyse Relationships?",
    "text": "Why Analyse Relationships?\nWe‚Äôve learned to ask ‚ÄúDoes A differ from B?‚Äù, but now we can ask, ‚ÄúHow do two measures move together?‚Äù\nIn this session, we‚Äôll explore the penguins dataset to see how body mass relates to flipper length, how bill length relates to bill depth, and how to identify relationships between continuous traits.",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#variables-framing",
    "href": "sessions/11-analysing-relationships/index.html#variables-framing",
    "title": "Analysing Penguins Relationships",
    "section": "Variables & Framing",
    "text": "Variables & Framing\nIn our previous session, comparing samples, we were comparing the average value of a continuous variable by groups (categorical variables).\nHere we will compare two continuous variables, considering how one variable (the outcome) changes in response to changes in the other variable (the predictor).\nThere is only a subtle difference between the idea of comparing samples and analysing relationships. You can frame a comparison between groups as analysing the relationship between the groups and the continuous variable, but you are still comparing the average value and dispersion for each group and inferring the relationship (or association) from this. When comparing two continuous variables, you can‚Äôt reduce either to their average, and are instead making statements about the way they vary together.\nQuestion: What relationships have you explored in your own work?",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#load-preview-penguins-data",
    "href": "sessions/11-analysing-relationships/index.html#load-preview-penguins-data",
    "title": "Analysing Penguins Relationships",
    "section": "Load & Preview Penguins Data",
    "text": "Load & Preview Penguins Data\n\nimport pandas as pd\n\n# load penguins data from TidyTuesday URL\nurl = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins.csv'\npenguins_raw = pd.read_csv(url)\npenguins_raw.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_len\nbill_dep\nflipper_len\nbody_mass\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nFocus: Drop rows with missing values in key numeric columns.\n\n# focus on key continuous variables and drop missing values\ndf = penguins_raw.dropna()\ndf.shape\n\n(333, 8)",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#visualing-relationships",
    "href": "sessions/11-analysing-relationships/index.html#visualing-relationships",
    "title": "Analysing Penguins Relationships",
    "section": "Visualing Relationships",
    "text": "Visualing Relationships\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# scatter of flipper length vs. body mass\nplt.figure(figsize=(8, 6))\nsns.scatterplot(\n    data=df,\n    x='flipper_len',\n    y='body_mass',\n    hue='species',\n    alpha=0.7\n)\nplt.title('The Relationship Between Flipper Length & Body Mass')\nplt.xlabel('Flipper Length (mm)')\nplt.ylabel('Body Mass (g)')\nplt.show()\n\n\n\n\n\n\n\nFigure¬†1\n\n\n\n\n\nQuestions:\n\nWhat pattern do you see in Figure¬†1?\nHow does body mass change when flipper length increases, according to this plot?\nAre there differences by species?\n\n\n# scatter of bill length vs. bill depth\nplt.figure(figsize=(8, 6))\nsns.scatterplot(\n    data=df,\n    x='bill_len',\n    y='bill_dep',\n    hue='species',\n    alpha=0.7\n)\nplt.title('The Relationship Between Bill Length & Bill Depth')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\nplt.show()\n\n\n\n\n\n\n\nFigure¬†2\n\n\n\n\n\nQuestions:\n\nWhat pattern do you see in Figure¬†2?\nHow does bill depth change when bill length increases, according to this plot?\nAre there differences by species?",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#computing-correlations",
    "href": "sessions/11-analysing-relationships/index.html#computing-correlations",
    "title": "Analysing Penguins Relationships",
    "section": "Computing Correlations",
    "text": "Computing Correlations\n\nPairwise Correlation\nWe can compute the correlation between two variables, using scipy.stats.\n\nfrom scipy.stats import pearsonr\n\nr, p = pearsonr(df['flipper_len'], df['body_mass'])\nprint(f\"Correlation (r) = {r:.2f}\")\n\nCorrelation (r) = 0.87\n\n\nA correlation of 0.87 is very strong. There is clearly a very strong association between flipper length and body mass. However, we can‚Äôt claim that flipper length causes body mass just based off this. Correlation does not imply causation1.\nWhen we visualised the relationship between bill length and bill depth, there appeared to be a grouping structure going on that complicated things, and the overall relationship appeared pretty noisy.\n\nr, p = pearsonr(df['bill_len'], df['bill_dep'])\nprint(f\"Correlation (r) = {r:.2f}\")\n\nCorrelation (r) = -0.23\n\n\nAs a result, the correlation score is much lower. A correlation of -0.23 tells us two things:\n\nThe negative correlation means that when bill length increases, bill depth tends to decrease.\nThe weaker correlation suggests that this decrease is a lot noisier, and it is much harder to estimate a penguin‚Äôs bill depth using their bill length.\n\nA correlation of +/- ~0.2 doesn‚Äôt necessarily mean there is no relationship. There are lots of ways correlation can mislead, because it is a limited measure. Visualising the relationship between bill length and bill depth showed us that species is highly relevant, and not factoring this in limits what we can say about this relationship.\n\n\nCorrelation Matrix\nWe may be interested in the pairwise correlation between multiple variables. If so, computing each correlation between pairs of variables is very cumbersome. Instead, we can compute a correlation matrix.\n\n# compute correlation matrix\n(\n    df.select_dtypes(include='number')\n    .corr()\n    .round(2)\n)\n\n\n\n\n\n\n\n\nbill_len\nbill_dep\nflipper_len\nbody_mass\nyear\n\n\n\n\nbill_len\n1.00\n-0.23\n0.65\n0.59\n0.03\n\n\nbill_dep\n-0.23\n1.00\n-0.58\n-0.47\n-0.05\n\n\nflipper_len\n0.65\n-0.58\n1.00\n0.87\n0.15\n\n\nbody_mass\n0.59\n-0.47\n0.87\n1.00\n0.02\n\n\nyear\n0.03\n-0.05\n0.15\n0.02\n1.00\n\n\n\n\n\n\n\nWe can also visualise a correlation matrix, shown below in Figure¬†3.\n\n# add correlation matrix to summarise relationships\ncorr_matrix = df.select_dtypes(include='number').corr()\n# plot heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title(\"Correlation Matrix\")\nplt.show()\n\n\n\n\n\n\n\nFigure¬†3\n\n\n\n\n\nIf you are concerned with a certain outcome and you want to quickly look at the correlation between all other continuous variables and the outcome, you can also compute this.\n\n# correlations of all numeric variables with body mass\n(\n    df.select_dtypes(include='number')\n    .corr()['body_mass']\n    .drop('body_mass')\n    .round(2)\n)\n\nbill_len       0.59\nbill_dep      -0.47\nflipper_len    0.87\nyear           0.02\nName: body_mass, dtype: float64",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#correlations-limitations",
    "href": "sessions/11-analysing-relationships/index.html#correlations-limitations",
    "title": "Analysing Penguins Relationships",
    "section": "Correlation‚Äôs Limitations",
    "text": "Correlation‚Äôs Limitations\nComputing correlation can be very informative, but there are a lot of ways it is limited. Correlation (at least the most common method for calculating correlation, Pearson‚Äôs r2) does not handle non-linearity well.\n\nimport numpy as np\n\n# simulate a u‚Äëshaped relationship example\nx_sim = np.linspace(-3, 3, 200)\ny_sim = x_sim**2 + np.random.normal(0, 1, 200)\nsim = pd.DataFrame({'x': x_sim, 'y': y_sim})\n\nplt.figure(figsize=(6, 4))\nsns.scatterplot(data=sim, x='x', y='y')\nplt.title('u-shaped pattern')\nplt.show()\n\n\n\n\n\n\n\nFigure¬†4\n\n\n\n\n\n\nr, p = pearsonr(sim['x'], sim['y'])\nprint(f\"Correlation (r) = {r:.2f}\")\n\nCorrelation (r) = -0.02\n\n\nTakeaway: Pearson‚Äôs r misses non-linear relationships",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#visualising-linear-regressions",
    "href": "sessions/11-analysing-relationships/index.html#visualising-linear-regressions",
    "title": "Analysing Penguins Relationships",
    "section": "Visualising Linear Regressions",
    "text": "Visualising Linear Regressions\n\n# add linear fit line\nsns.regplot(\n    data=df,\n    x='flipper_len',\n    y='body_mass',\n    scatter=True,\n    ci=95\n)\nplt.title('Adding a Regression Line')\nplt.xlabel('Flipper Length (mm)')\nplt.ylabel('Body Mass (g)')\nplt.show()\n\n\n\n\n\n\n\nFigure¬†5\n\n\n\n\n\n\n# add linear fit line\nsns.regplot(\n    data=df,\n    x='bill_len',\n    y='bill_dep',\n    scatter=True,\n    ci=95\n)\nplt.title('Adding a Regression Line')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\nplt.show()\n\n\n\n\n\n\n\nFigure¬†6",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#visualisation-limitations",
    "href": "sessions/11-analysing-relationships/index.html#visualisation-limitations",
    "title": "Analysing Penguins Relationships",
    "section": "Visualisation Limitations",
    "text": "Visualisation Limitations\nVisualising relationships has many of the same issues that computing correlation does, but fundamentally the biggest issue is that it is pairwise, and few relationships are strictly pairwise in the real world.\nFigure¬†6 points to another limitation with Pearson‚Äôs r that also applies to regression plots. Grouping structures!\n\nsns.lmplot(data=df, x=\"bill_len\", y=\"bill_dep\", hue=\"species\")\n\nplt.title('Accounting for groups')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\nplt.show()\n\n\n\n\n\n\n\nFigure¬†7\n\n\n\n\n\nFigure¬†7 shows how pairwise examination of relationships can miss so much.\nDrawing a straight line through data is strictly linear, but unlike correlation coefficients, you will be able to see when this is inappropriate. A linear regression plot will not handle the non-linear pattern above any better than a correlation coefficient, but you will be able to see the problem for yourself.\nVisualising data helps you to get a sense of how two variables are related, but where you are seeking to understand the relationship between variables, or even explain what causes a certain outcome, you have to go further.",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#summary",
    "href": "sessions/11-analysing-relationships/index.html#summary",
    "title": "Analysing Penguins Relationships",
    "section": "Summary",
    "text": "Summary\n\nCorrelation quantifies strength of linear link.\nOnly linear, pairwise, no adjustment for other variables.\nCorrelation does not imply causation (but does not not imply causation, either).",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/11-analysing-relationships/index.html#footnotes",
    "href": "sessions/11-analysing-relationships/index.html#footnotes",
    "title": "Analysing Penguins Relationships",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCorrelation might not imply causation, but it is important to realise that the presence of correlation does not mean causation is not present. You just can‚Äôt conclude causation exists simply because you observe a correlation.‚Ü©Ô∏é\nThere are a number of other ways of calculating correlation, including methods that account for non-linearity, but more often than not you will encounter Pearson‚Äôs r. Any time correlation is mentioned without specifying the way it was calculated, you should assume it is using Pearson‚Äôs r.‚Ü©Ô∏é",
    "crumbs": [
      "Sessions",
      "Data Science",
      "11. Analysing Relationships"
    ]
  },
  {
    "objectID": "sessions/01-onboarding/index.html",
    "href": "sessions/01-onboarding/index.html",
    "title": "Python Onboarding",
    "section": "",
    "text": "This is the first session of Code Club‚Äôs relaunch. It focuses on giving users all the tools they need to get started using Python and demonstrates the setup for a typical Python project.",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "1. Python Onboarding"
    ]
  },
  {
    "objectID": "sessions/01-onboarding/index.html#session-slides",
    "href": "sessions/01-onboarding/index.html#session-slides",
    "title": "Python Onboarding",
    "section": "Session Slides",
    "text": "Session Slides\nUse the left ‚¨ÖÔ∏è and right ‚û°Ô∏è arrow keys to navigate through the slides below. To view in a separate tab/window, follow this link.",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "1. Python Onboarding"
    ]
  },
  {
    "objectID": "sessions/01-onboarding/index.html#the-tools-you-will-need",
    "href": "sessions/01-onboarding/index.html#the-tools-you-will-need",
    "title": "Python Onboarding",
    "section": "The Tools You Will Need",
    "text": "The Tools You Will Need\nWhile this course focuses on Python, we will use several other tools throughout.\n\nLanguage: Python\nDependency Management & Virtual Environments: uv\nVersion Control: Git, GitHub Desktop\nIDE: VS Code/Jupyter Notebooks (or your preferred IDE)\n\nYou can install all the tools you‚Äôll need by running the following one-liner run in PowerShell:\nwinget install astral-sh.uv Microsoft.VisualStudioCode github-desktop\n\nPython\nPython is an all-purpose programming language that is one of, if not the most popular, in the world1 and is widely used in almost every industry. Its popularity is owed to its flexibility as a language that can be used to achieve nearly any job. It is often referred to as the second-best tool for every job. Specialist languages might be better for specific tasks (for example, R for statistics), but Python is good at everything.\nIt is a strong choice for data science and analytics, being one of the best languages for data wrangling, data visualisation, statistics, and machine learning. It is also well-suited to web development, scientific computing, and automation.\n\n\nDependency Management\nOne of Python‚Äôs greatest weaknesses is dependency management. Despite its many strengths, there is no escaping the dependency hell that every Python user faces.\nDependency management refers to the process of tracking and managing all of the packages (dependencies) a project needs to run. It is a consideration in any programming language. It ensures:\n\nThe right packages are installed.\nThe correct versions are used.\nConflicts between packages are avoided.\n\nThere are many reasons that Python handles dependency management so poorly, but there are some tools that make this a little easier on users. We are using uv for dependency management. It is relatively new, but it is quickly becoming the consensus tool for dependency management in Python because it makes the process about as painless as it can be without moving to a different language entirely.\n\nVirtual Environments\nVirtual environments are a component of dependency management. Dependency management becomes much messier when you have many Python projects, each using their own packages, some overlapping and some requiring specific versions, either for compatibility or functionality reasons. Reducing some of this friction by isolating each project in its own virtual environment, like each project is walled off from all other projects, makes dependency management a little easier. Virtual environments allow you to manage dependencies for a specific project without the state of those dependencies affecting other projects or your wider system.\nVirtual environments help by:\n\nKeeping dependencies separate for each project.\nAvoiding version conflicts between projects.\nMaking dependency management more predictable and reproducible.\n\nWe will use uv to manage all dependencies, virtual environments, and even versions of Python.\n\n\n\nVersion Control\nVersion control is the practice of tracking and managing changes to code or files over time, allowing you to:\n\nRevert to earlier versions if needed.\nCollaborate with others on the same project easily.\nMaintain a history of changes.\n\nWe are using Git, a version control system, to host our work and GitHub Desktop to manage version control locally.\nVersion control and Git are topics entirely in their own right, and covering them in detail is out of the scope of this session. We hope to cover version control in a future session, but right now, you just need to be able to access materials for these sessions. You can find the materials in the Code Club repository.\nIf you have downloaded GitHub Desktop, the easiest way to access these materials and keep up-to-date is by cloning the Code Club repository (go to File, then Clone Repository, select URL, and paste the Code Club repository link in the URL field). You can then ensure that the materials you are using are the most current by clicking the Fetch Origin button in GitHub Desktop, which grabs the changes we‚Äôve made from the central repository on GitHub.\n\n\nIDE\nIDEs (Integrated Development Environments) are software that simplifies programming and development by combining many of the most common tasks and helpful features for programming into a single tool. These typically include a code editor, debugging functionality, build tools, and features like syntax highlighting and code completion. When you start your code journey, you might not need all these tools, and fully-featured IDEs can be overwhelming. But as you become more comfortable with programming, all these different features will become very valuable.\nSome common IDEs that are used for Python include:\n\nVS Code\nPyCharm\nVim\nJupyter Notebooks/JupyterLab\nPositron\n\nWe will use VS Code or Jupyter Notebooks (which is not exactly an IDE but is similar).",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "1. Python Onboarding"
    ]
  },
  {
    "objectID": "sessions/01-onboarding/index.html#project-setup",
    "href": "sessions/01-onboarding/index.html#project-setup",
    "title": "Python Onboarding",
    "section": "Project Setup",
    "text": "Project Setup\nEvery new Python project should start with using uv to set up a virtual environment for the project to keep everything organised and reduce the risk of finding yourself in dependency hell.\nThe entire project setup process can be handled in the command line. We will use PowerShell for consistency.\nWhen you open a PowerShell window, it should open in your C drive (e.g.,¬† C:\\Users\\user.name). If it does not, run cd ~, and it should return to your home directory.\nWe will create a new uv project in the home directory2 using the command uv init. The new project will contain everything we need, including a Python installation, a virtual environment, and the necessary project files for tracking and managing any packages installed in the virtual environment. To set up a new project called test-project, use the following command:\nuv init test-project\nHaving created this new directory, navigate to it using cd test-project. You can check the files in a directory using the command ls. If you run this command, you will see three files in the project directory (hello.py, pyproject.toml, and README.md). The project doesn‚Äôt yet have a Python installation or a virtual environment, but this will be added when we add external Python packages.\nYou can install Python packages using the command uv add. We can add some common Python packages that we will use in most projects (pandas, numpy, seaborn, and ipykernel3) using the following command:\nuv add pandas numpy seaborn ipykernel\nThe output from this command will reference the Python installation used and the creation of a virtual environment directory .venv. Now, if you run ls, you will see two new items in the directory, uv.lock and .venv.\nYour Python project is now set up, and you are ready to start writing some code. You can open VS Code from your PowerShell window by running code ..\nFor more information about creating and managing projects using uv, check out the uv documentation.\n\nOpening your project in VS Code\nTo open your newly-created uv project in VS Code, launch the application and click File &gt; Open Folder.... You‚Äôll want to make sure you select the root level of your project. Once you‚Äôve opened the folder, the file navigation pane in VS Code should display the files that uv has created, including a main.py example file. Click on this to open it.\nOnce VS Code realises you‚Äôve opened a folder with Python code and a virtual environment, it should do the following:\n\nSuggest you install the Python extension (and, once you‚Äôve created a Jupyter notebook, the Jupyter one) offered by Microsoft - go ahead and do this. If this doesn‚Äôt happen, you can install extensions manually from the Extensions pane on the left-hand side.\nSelect the uv-created .venv as the python Environment we‚Äôre going to use to actually run our code. If this doesn‚Äôt happen, press ctrl-shift-P, type ‚Äúpython environment‚Äù to find the Python - Create Environment... option, hit enter, choose ‚ÄúVenv‚Äù and proceed to ‚ÄúUse Existing‚Äù.\n\nIf all has gone well, you should be able to hit the ‚Äúplay‚Äù icon in the top right to execute main.py. The Terminal pane should open up below and display something like Hello from (your-project-name)!.",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "1. Python Onboarding"
    ]
  },
  {
    "objectID": "sessions/01-onboarding/index.html#footnotes",
    "href": "sessions/01-onboarding/index.html#footnotes",
    "title": "Python Onboarding",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlthough there are several ways to measure language popularity, the PYPL Index, HackerRank‚Äôs Developer Skills Report, and IEEE Spectrum all rank Python as the most popular language in the world, while Stack Overflow‚Äôs Developer Survey places Python third behind JavaScript and HTML/CSS.‚Ü©Ô∏é\nWe recommend using the C drive for all Python projects, especially if using version control. Storing projects like these on One Drive will create many unnecessary issues.‚Ü©Ô∏é\nStrictly speaking, we should install ipykernel as a development dependency (a dependency that is needed for any development but not when the project is put into production). In this case, we would add it by running uv add --dev ipykernel. However, in this case, it is simpler to just add it as a regular dependency, and it doesn‚Äôt harm.‚Ü©Ô∏é",
    "crumbs": [
      "Sessions",
      "Onboarding",
      "1. Python Onboarding"
    ]
  },
  {
    "objectID": "resources/glossary.html",
    "href": "resources/glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "This page will have a list of definitions for commonly used (and/or commonly misunderstood) terminology and acronyms relating to python or data analysis and manipulation in general.\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n  Term\n  Definition\n\n\n\n  \n    Exploratory Data Analysis (EDA)\n    The process of analysing datasets to summarise their main characteristics, often using visual methods, before formal modeling.\n  \n  \n    Functional programming\n    A programming paradigm that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data.\n  \n  \n    Git\n    A distributed version control system used to track changes in source code during software development.\n  \n  \n    GitHub\n    A cloud-based platform that provides hosting for repositories of files and folders (usually of software code) using git as its backend for version control.\n  \n  \n    Jupyter\n    A software package that allows the creation of python notebooks that can include a mixture of markdown-formatted text and live Python code.\n  \n  \n    Markdown (.md)\n    A simple plain-text markup scheme designed to allow for rapid production of formatted text (with headings, links, etc) within a plaintext file. Used by Quarto (as a Quarto-specific flavour with the .qmd extension).\n  \n  \n    matplotlib\n    The baseline Python library for creating static, animated, and interactive visualisations, offering extensive customisation options for plots and charts. Also used as a framework for more advanced or visually pleasing visualisation packages like seaborn.\n  \n  \n    Object-oriented programming (OOP)\n    A programming paradigm based on the concept of \"objects,\" which can contain data and code to manipulate that data.\n  \n  \n    pandas\n    A python data analysis and manipulation library for working with dataframes (tabular data)\n  \n  \n    Python\n    A general-purpose programming language\n  \n  \n    Regression\n    A method for modeling the relationship between one or more explanatory variables and an outcome. It is used to predict outcomes and understand the impact of changes in predictors (explanatory variables) on the response (outcome).\n  \n  \n    Repository (repo)\n    In git and github, a repository is a self-contained \"project\" of files and folders.\n  \n  \n    Reproducible Analytical Pipelines (RAP)\n    A set of processes and tools designed to ensure that data analysis can be consistently repeated and verified by others.\n  \n  \n    seaborn (sns)\n    A Python data visualisation library based on Matplotlib, providing a high-level interface for drawing attractive and informative statistical graphics.\n  \n  \n    TOML\n    Tom's Obvious Minimal Language - simple, human-readable data serialisation format designed for configuration files, emphasizing readability and ease of use. Used by uv to specify its projects.\n  \n  \n    uv\n    A Python package manager, which can manage python projects (folders) and manage the installation and management of the python environment and libraries within that folder.\n  \n  \n    YAML\n    Yet Another Markup Language - a human-readable data serialisation format often used for configuration files and data exchange between languages."
  },
  {
    "objectID": "sessions/01-onboarding/slides.html#what-to-expect",
    "href": "sessions/01-onboarding/slides.html#what-to-expect",
    "title": "Python Onboarding",
    "section": "What to Expect?",
    "text": "What to Expect?\n\nLearning a language is hard. It can be frustrating. Perseverance is key to success.\nThese sessions will introduce you to Python, showing you what is possible and how to achieve some of what might benefit your work.\nBut the real learning comes by doing. You need to run the code yourself, have a play around, and cement what you‚Äôve learned by applying it.\nPractice, repetition, and making mistakes along the way is how real progress is made."
  },
  {
    "objectID": "sessions/01-onboarding/slides.html#why-learn-python",
    "href": "sessions/01-onboarding/slides.html#why-learn-python",
    "title": "Python Onboarding",
    "section": "Why Learn Python?",
    "text": "Why Learn Python?\n\nCoding skills, generally, and Python specifically, seem to be a priority in the NHS right now. It‚Äôs a clear direction of travel. Learning now sets you up for the future.\nPython and the applied skills taught in these sessions will enable you to use advanced methods and design flexible, scalable solutions.\nPython is very valuable for career development.\nIt is (hopefully) fun!"
  },
  {
    "objectID": "sessions/01-onboarding/slides.html#the-toolkit",
    "href": "sessions/01-onboarding/slides.html#the-toolkit",
    "title": "Python Onboarding",
    "section": "The Toolkit",
    "text": "The Toolkit\n\nWe will be using the following tools throughout this course:\n\nLanguage: Python\nDependency management: uv\nVersion Control: Git, GitHub Desktop\nIDE: VS Code/Jupyter Notebooks (or your preferred IDE)\n\nYou can install all these tools by running the following in PowerShell:\n\nwinget install astral-sh.uv Microsoft.VisualStudioCode github-desktop"
  },
  {
    "objectID": "sessions/01-onboarding/slides.html#python",
    "href": "sessions/01-onboarding/slides.html#python",
    "title": "Python Onboarding",
    "section": "Python",
    "text": "Python\n\nPython is an all-purpose programming language that is the most popular worldwide and widely used in almost every industry.\nPython‚Äôs popularity is owed to its flexibility ‚Äì it is the second-best tool for every job.\nIt is a strong choice for data science and analytics, being one of the best languages for data wrangling, data visualisation, statistics, and machine learning.\n\nIt is also well-suited to web development, scientific computing, and automation."
  },
  {
    "objectID": "sessions/01-onboarding/slides.html#dependency-management",
    "href": "sessions/01-onboarding/slides.html#dependency-management",
    "title": "Python Onboarding",
    "section": "Dependency Management",
    "text": "Dependency Management\n\nDependency management refers to the process of tracking and managing all of the packages (dependencies) a project needs to run. It ensures:\n\nThe right packages are installed.\nThe correct versions are used.\nConflicts between packages are avoided.\n\nWe are using uv for dependency management."
  },
  {
    "objectID": "sessions/01-onboarding/slides.html#virtual-environments",
    "href": "sessions/01-onboarding/slides.html#virtual-environments",
    "title": "Python Onboarding",
    "section": "Virtual Environments",
    "text": "Virtual Environments\n\nVirtual environments are isolated Python environments that allow you to manage dependencies for a specific project without the state of those dependencies affecting other projects or your wider system. They help by:\n\nKeeping dependencies separate for each project.\nAvoiding version conflicts between projects.\nMaking dependency management more predictable and reproducible.\n\nVirtual environments are a part of dependency management, and we will use uv to manage both the dependencies and virtual environments."
  },
  {
    "objectID": "sessions/01-onboarding/slides.html#version-control",
    "href": "sessions/01-onboarding/slides.html#version-control",
    "title": "Python Onboarding",
    "section": "Version Control",
    "text": "Version Control\n\nVersion control is the practice of tracking and managing changes to code or files over time, allowing you to:\n\nRevert to earlier versions if needed.\nCollaborate with others on the same project easily.\nMaintain a history of changes.\n\nWe are using Git (the version control system) and GitHub (the platform for hosting our work)."
  },
  {
    "objectID": "sessions/01-onboarding/slides.html#ide",
    "href": "sessions/01-onboarding/slides.html#ide",
    "title": "Python Onboarding",
    "section": "IDE",
    "text": "IDE\n\nAn IDE (Integrated Development Environment) is fully featured software that provides everything you need to write code as conveniently as possible.\nIt typically includes a code editor, debugger, build tools, and features like syntax highlighting and code completion.\nSome common IDEs used for Python include VS Code, PyCharm, Vim, Jupyter Notebooks/JupyterLab, and Positron.\nWe will use VS Code or Jupyter Notebooks (which is not exactly an IDE but is similar)."
  },
  {
    "objectID": "sessions/schedule.html",
    "href": "sessions/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "This is the schedule for Code Club in FY25/26.\nThe Demonstration, Presentation, and Notebook columns indicate the content to be expected for each session:\n\nDemonstration: A live show-and-tell relating to the discussion topic.\nPresentation: A slide deck covering the discussion topic.\nNotebook: A Jupyter Notebook containing code-along elements or examples for people to work through after the session.\n\nTutorials will be divided into Modules. We recommend that people attend or watch tutorials in the Core module in order to gain a fundamental understanding of coding concepts and resources. Further modules are to be confirmed, but will likely include Automation, Dashboards and Visualisation, and Data Science. People will be able to attend those modules that interest them.\nWe have mapped the contents of the syllabus to competencies in the National Competency Framework for Data Professionals in Health and Care so that you can see which sessions will help you on your way towards them. For full details of the skills in the framework, the self-assessment tool can be found on FutureNHS.\nPlease note that this is a first draft of the mapping of NCF competencies to our syllabus and it is awaiting review.\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  Session Date\n  Module\n  Session Name\n  Description\n  Demonstration\n  Presentation\n  Notebook\n  NCF Competency\n\n\n\n  \n    22/04/2025\n    N/A\n    Nectar Re-Launch\n    Showcasing the re-launch of Code Club\n    üé¨\n    üíª\n    -\n    -\n  \n  \n    01/05/2025\n    On-boarding\n     Python On-boarding\n    What to install, basic virtual environment management, introduction to VS Code\n    üé¨\n    -\n    -\n    SA21 : Python Proficiency\n  \n  \n    15/05/2025\n    On-boarding\n    Jupyter Notebooks\n    Demonstration of Jupyter Notebooks\n    üé¨\n    -\n    üìñ\n    SA21 : Python Proficiency\n  \n  \n    29/05/2025\n    Visualisation\n    EDA and Visualisations\n    Introduction to Exploratory Data Analysis and how to visualise it\n    üé¨\n    -\n    üìñ\n    SA4 : Descriptive and Explicative Analytics\n  \n  \n    12/06/2025\n    Visualisation\n    Visualisation with Seaborn\n    Aesthetically-pleasing visualisations\n    üé¨\n    -\n    üìñ\n    SA1 : Data Visualisation\n  \n  \n    26/06/2025\n    Core concepts\n    Data Types\n    Introduction to Data Types\n    -\n    üíª\n    üìñ\n    SA21 : Python Proficiency\n  \n  \n    10/07/2025\n    Core concepts\n    Control Flow\n    Introduction to Control Flow\n    -\n    üíª\n    üìñ\n    SA21 : Python Proficiency\n  \n  \n    24/07/2025\n    Core concepts\n    Functions & Functional Programming\n    Introduction to Functions and Functional Programming\n    -\n    üíª\n    üìñ\n    SA21 : Python Proficiency\n  \n  \n    07/08/2025\n    Core concepts\n    Object-Oriented Programming\n    Introduction to Object-Oriented Programming\n    -\n    üíª\n    üìñ\n    SA21 : Python Proficiency\n  \n  \n    21/08/2025\n    Visualisation\n    Streamlit dashboards\n    How to present data (visualisations) in a Streamlit dashboard\n    üé¨\n    -\n    -\n    SA1 : Data Visualisation\n  \n  \n    04/09/2025\n    Data Science\n    Comparing Samples\n    Understanding data distributions and comparisons between samples\n    -\n    üíª\n    üìñ\n    SA4 : Descriptive and Explicative Analytics\n  \n  \n    18/09/2025\n    Data Science\n    Analysing Relationships\n    Quantifying relationships with hypothesis tests and statistical significance\n    -\n    üíª\n    üìñ\n    SA15 : Hypothesis Testing\n  \n  \n    02/10/2025\n    Data Science\n    Introduction to Linear Regression\n    Introduction to regression concepts and the component parts of linear regression\n    -\n    üíª\n    üìñ\n    SA7 : Advanced Statistics\n  \n  \n    16/10/2025\n    Data Science\n    Implementing Linear Regression\n    Building linear models, assessing model fit, and interpreting coefficients\n    üé¨\n    üíª\n    üìñ\n    SA7 : Advanced Statistics\n  \n  \n    30/10/2025\n    Data Science\n    Beyond Linearity\n    Introduction to generalised linear regression models\n    üé¨\n    üíª\n    üìñ\n    SA7 : Advanced Statistics",
    "crumbs": [
      "Sessions",
      "Session Schedule"
    ]
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/slides.html#what-is-a-notebook",
    "href": "sessions/02-jupyter_notebooks/slides.html#what-is-a-notebook",
    "title": "Jupyter Notebooks",
    "section": "What is a notebook",
    "text": "What is a notebook\n\nThe standard for programming in python is the .py file which can hold a block of code which can contain lines of code that allow you to export the results as visualisations or data files.\nJupyter Notebooks have been developed with the data science and analytical community.\nNotebooks are a collection interactive cells which a user can run as a collection or individually, based on the current state of program.\nCells can be denoted as Code, Markdown or Raw Depending on use case.\n\nCode cells use a process called a kernel to run programme elements in the user selected code base (e.g.¬†Python or R).\nMarkdown cells allow the user to include formatted text and other elements (such as links and images).\nRaw cells have no processing attached and output as plain text."
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/slides.html#a-brief-history-of-jupyter-notebooks",
    "href": "sessions/02-jupyter_notebooks/slides.html#a-brief-history-of-jupyter-notebooks",
    "title": "Jupyter Notebooks",
    "section": "A brief history of Jupyter notebooks",
    "text": "A brief history of Jupyter notebooks\n\nIn 2001, Fernando Perez started development of the iPython project as a way of incorporating prompts and access to previous output, as he continued development he amalgamated iPython with 2 other projects\nIn 2014, Project Jupyter was born out of the initial iPython project. The key aim was to make the project independent of a programming language and allow different code bases to use notebooks. The Name is a reference to the three initial languages: Julia, Python, and R.\nJupyter Notebooks and more recently Jupiter Labs are more than just the notebook, they are interactive development environments launched from the command line.\nJupyter notebooks are used by many online platforms and service providers including: Kaggle, Microsoft Fabric, and the NHS Federated Data Platform."
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/slides.html#pros-and-cons-of-using-a-notebook",
    "href": "sessions/02-jupyter_notebooks/slides.html#pros-and-cons-of-using-a-notebook",
    "title": "Jupyter Notebooks",
    "section": "Pros and cons of using a notebook",
    "text": "Pros and cons of using a notebook\nOn the plus side‚Ä¶\n\nNotebooks are highly interactive and allow cells to be run in any order.\nYou can re-run each cell separately, so iterative testing is more granular.\nNotebooks can be used to provide a structured report for an end user regardless of coding knowledge.\n\nHaving said that‚Ä¶\n\nIf you are not careful you can save a notebook in a state that cannot run as intended if changes are not checked.\nIt can be harder to understand complex code interactions."
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/slides.html#the-toolkit",
    "href": "sessions/02-jupyter_notebooks/slides.html#the-toolkit",
    "title": "Jupyter Notebooks",
    "section": "The Toolkit",
    "text": "The Toolkit\n\nYou will need the following pre-installed:\n\nLanguage: Python\nDependency management: uv\nVersion Control: Git, GitHub Desktop\nIDE: VS Code (or your preferred IDE)\n\nYou can install all these tools by running the following in PowerShell:\n\nwinget install astral-sh.uv Microsoft.VisualStudioCode github-desktop"
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/slides.html#walkthrough-and-demonstration",
    "href": "sessions/02-jupyter_notebooks/slides.html#walkthrough-and-demonstration",
    "title": "Jupyter Notebooks",
    "section": "Walkthrough and demonstration",
    "text": "Walkthrough and demonstration\nif reviewing these slides this section is only available in the recording, though the initial steps used should be available on the associated Code Club site page"
  },
  {
    "objectID": "sessions/02-jupyter_notebooks/slides.html#resources",
    "href": "sessions/02-jupyter_notebooks/slides.html#resources",
    "title": "Jupyter Notebooks",
    "section": "Resources",
    "text": "Resources\n\nCheck out the History of iPython\nYou can find out more about Project Jupyter\nThe demonstration makes use of this markdown cheatsheet\nLikewise this is the Jupyter shortcuts Cheat Sheet"
  }
]