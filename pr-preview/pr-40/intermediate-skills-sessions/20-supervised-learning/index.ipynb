{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervised Learning\n",
        "\n",
        "This is the second session in our machine learning series. In the first\n",
        "session, we introduced machine learning conceptually and demonstrated a\n",
        "basic supervised learning workflow using logistic regression to predict\n",
        "survivors on the Titanic. This session builds on what was covered in the\n",
        "first session, exploring supervised learning in more detail,\n",
        "understanding the different approaches to supervising learning, and\n",
        "looking at some of the most common algorithms for supervised tasks.\n",
        "\n",
        "## Slides\n",
        "\n",
        "Use the left ⬅️ and right ➡️ arrow keys to navigate through the slides\n",
        "below. To view in a separate tab/window,\n",
        "<a href=\"slides.html\" target=\"_blank\">follow this link</a>."
      ],
      "id": "cb3a91bb-b5b3-4e11-939f-9dcb3a02c2ad"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<iframe src=\"slides.html\" height=\"500\" width=\"100%\">"
      ],
      "id": "29e9a807-8bbe-4ffe-897d-62510d3d690b"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</iframe>"
      ],
      "id": "3bb6866f-ba4a-48ca-b0e8-c174bf247d1c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Supervised Learning\n",
        "\n",
        "Supervised learning means training a model on data where the outcome is\n",
        "already known, in order to predict outcomes on new data where the answer\n",
        "isn’t known. You provide features (input variables) and a target (the\n",
        "outcome to predict), and the model learns the relationship between them.\n",
        "This differs from unsupervised learning, where no target exists and the\n",
        "goal is finding patterns or groupings, and from reinforcement learning,\n",
        "where the model learns through trial and error.\n",
        "\n",
        "The fundamental structure of supervised learning involves features and\n",
        "targets. Features are the input variables that describe each\n",
        "observation: patient age, diagnosis codes, medication count, previous\n",
        "admissions. The target is what you want to predict: whether the patient\n",
        "will be readmitted, how long they’ll stay, which treatment will work\n",
        "best. Features can be numerical (age, test results) or categorical\n",
        "(diagnosis, sex), and most algorithms handle both types.\n",
        "\n",
        "There are two different kinds of supervised learning task, based on the\n",
        "target type:\n",
        "\n",
        "-   Classification - Predicting categories (often binary outcomes). Will\n",
        "    this patient be readmitted (yes/no), which diagnosis applies (A, B,\n",
        "    C, D), is this scan normal or abnormal.\n",
        "-   Regression - Predicting continuous numbers. How many days will the\n",
        "    patient stay, what will next month’s A&E attendances be, what’s the\n",
        "    predicted blood pressure.\n",
        "\n",
        "Some algorithms work for both tasks. Decision trees, for instance, can\n",
        "do classification by predicting the most common class in each leaf node,\n",
        "or regression by predicting the average value in each leaf.\n",
        "\n",
        "The workflow we introduced in Session 1 applies to all supervised\n",
        "learning. Get labelled data, split into training and testing sets, train\n",
        "a model on training data, predict on test data, evaluate performance.\n",
        "The training/testing split is critical because it simulates real-world\n",
        "deployment. The model learns patterns from training data, then we test\n",
        "whether those patterns generalise to new data. Testing on training data\n",
        "would be dishonest: the model has already seen those examples and\n",
        "optimised for them.\n",
        "\n",
        "The central challenge in supervised learning is generalisation. Models\n",
        "must learn patterns that work on new data, not just memorise the\n",
        "training set. Underfitting occurs when the model is too simple and\n",
        "misses important patterns, performing poorly on both training and test\n",
        "data. Overfitting occurs when the model is too complex and learns noise\n",
        "in the training data, performing well on training data but poorly on\n",
        "test data. Finding the right complexity level is fundamental to building\n",
        "useful models.\n",
        "\n",
        "## Understanding How Models Learn\n",
        "\n",
        "When analysts first encounter machine learning, the training process\n",
        "often feels like magic. You pass data into a function, get a trained\n",
        "model back, and somehow it can make predictions. Understanding what\n",
        "happens during training transforms machine learning from magic into a\n",
        "tool you can control and apply effectively.\n",
        "\n",
        "Different algorithms approach learning in fundamentally different ways.\n",
        "Logistic regression finds linear boundaries that separate classes.\n",
        "Decision trees ask sequential yes/no questions. Random forests combine\n",
        "many trees to get more stable predictions. Gradient boosting builds\n",
        "trees that learn from previous mistakes. Each approach has strengths and\n",
        "weaknesses that make it better suited to different types of problems.\n",
        "\n",
        "This matters in practice because there is no single best algorithm. The\n",
        "model that works best depends on your data structure, how much data you\n",
        "have, whether you need to explain predictions to clinicians, and what\n",
        "types of patterns exist in your features. Understanding how algorithms\n",
        "work lets you make informed choices about which to try and how to\n",
        "interpret their results.\n",
        "\n",
        "## Comparing Multiple Models\n",
        "\n",
        "We’ll train four different models on the Titanic dataset and compare\n",
        "their performance. This demonstrates how different algorithms learn\n",
        "different patterns from the same data.\n",
        "\n",
        "### Setup\n",
        "\n",
        "We’ll use the same libraries as Session 1, with additions for tree-based\n",
        "models and visualisation."
      ],
      "id": "31b57714-e833-4a71-b57c-f1006501e28e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# set random seed for reproducibility\n",
        "np.random.seed(42)"
      ],
      "id": "setup"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preparation\n",
        "\n",
        "We’ll follow the same workflow as Session 1, preparing the Titanic\n",
        "dataset for modelling."
      ],
      "id": "2ac119d9-2a6a-4c44-960e-1c9d3e30fefb"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load titanic data\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# select features and target\n",
        "X = df[['pclass', 'sex', 'age', 'fare']]\n",
        "y = df['survived']\n",
        "\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# prepare features\n",
        "def prepare_features(data):\n",
        "    data = data.copy()\n",
        "    data['age'] = data['age'].fillna(data['age'].median())\n",
        "    data['sex'] = (data['sex'] == 'female').astype(int)\n",
        "    return data\n",
        "\n",
        "X_train = prepare_features(X_train)\n",
        "X_test = prepare_features(X_test)"
      ],
      "id": "load-and-prep-data"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression\n",
        "\n",
        "We already covered logistic regression in Session 1. It finds a linear\n",
        "boundary that best separates survivors from non-survivors in feature\n",
        "space. Logistic regression works well when the relationship between\n",
        "features and outcomes is approximately linear, and it produces\n",
        "interpretable coefficients that show how each feature influences\n",
        "predictions."
      ],
      "id": "fee802d3-ba9e-45ef-8834-039382b92588"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 79.5%"
          ]
        }
      ],
      "source": [
        "# train logistic regression\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# evaluate on test set\n",
        "lr_pred = lr_model.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.1%}\")"
      ],
      "id": "logistic-regression"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decision Trees\n",
        "\n",
        "Decision trees learn by recursively splitting the data based on feature\n",
        "values. At each node, the tree asks a yes/no question about a feature\n",
        "and splits passengers into two groups. The algorithm chooses splits that\n",
        "best separate survivors from non-survivors, measured by metrics like\n",
        "Gini impurity[1].\n",
        "\n",
        "The tree continues splitting until it reaches stopping criteria: all\n",
        "passengers in a node have the same outcome, the node contains too few\n",
        "passengers to split further, or the tree reaches its maximum depth. The\n",
        "result is a series of rules that can be followed from root to leaf to\n",
        "make a prediction.\n",
        "\n",
        "[1] Gini impurity measures how mixed the classes are in a node. A pure\n",
        "node (all survivors or all deaths) has Gini = 0. A 50/50 split has Gini\n",
        "= 0.5. The algorithm chooses splits that minimise Gini impurity."
      ],
      "id": "256d8393-8f0c-4705-976d-4d79dd676d3d"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 80.6%"
          ]
        }
      ],
      "source": [
        "# train decision tree\n",
        "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# evaluate on test set\n",
        "tree_pred = tree_model.predict(X_test)\n",
        "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {tree_accuracy:.1%}\")"
      ],
      "id": "decision-tree"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualise the tree structure to see exactly what rules it\n",
        "learned."
      ],
      "id": "d7569390-cd69-4fc6-8e65-e35943c52889"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(\n",
        "    tree_model, \n",
        "    feature_names=X_train.columns,\n",
        "    class_names=['Died', 'Survived'],\n",
        "    filled=True,\n",
        "    fontsize=10\n",
        ")\n",
        "plt.title(\"Decision Tree Structure (max_depth=3)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-visualise-tree"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The tree shows the splitting logic clearly. Each box contains the\n",
        "splitting rule, the Gini impurity, the number of samples, and the\n",
        "predicted class. Following any path from root to leaf gives you the\n",
        "sequence of decisions that lead to a prediction. For example, if a\n",
        "passenger is female (sex ≤ 0.5 is false), the tree predicts survival\n",
        "regardless of other features.\n",
        "\n",
        "This interpretability is the key strength of decision trees. You can\n",
        "explain exactly why a model made a specific prediction by showing the\n",
        "decision path. However, trees have a significant weakness: they tend to\n",
        "overfit the training data by learning overly specific rules that don’t\n",
        "generalise well.\n",
        "\n",
        "### Random Forests\n",
        "\n",
        "Random forests address the overfitting problem by training many trees\n",
        "and combining their predictions. Each tree in the forest is trained on a\n",
        "random subset of the training data (bootstrap sample), and at each\n",
        "split, only a random subset of features is considered. This randomness\n",
        "ensures each tree learns slightly different patterns.\n",
        "\n",
        "When making predictions, each tree votes for a class, and the forest\n",
        "returns the majority vote. Because individual trees make different\n",
        "mistakes, averaging across trees produces more reliable predictions that\n",
        "generalise better to new data."
      ],
      "id": "626fee70-cc31-4f8d-9315-c46cce4a0025"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 78.7%"
          ]
        }
      ],
      "source": [
        "# train random forest\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,  # number of trees\n",
        "    max_depth=3,       # keep trees shallow to match single tree\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# evaluate on test set\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.1%}\")"
      ],
      "id": "random-forest"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random forests typically outperform single decision trees because the\n",
        "ensemble smooths out individual tree errors. The trade-off is reduced\n",
        "interpretability: you can’t easily visualise 100 trees or explain a\n",
        "prediction as a single decision path.\n",
        "\n",
        "### Gradient Boosting\n",
        "\n",
        "Gradient boosting takes a different approach to combining trees. Instead\n",
        "of training trees independently and averaging, it trains them\n",
        "sequentially. Each new tree focuses on the mistakes made by previous\n",
        "trees, gradually improving the model’s performance.\n",
        "\n",
        "The process works as follows: train the first tree on the original data,\n",
        "identify where it makes prediction errors, train the second tree to\n",
        "correct those errors, and repeat. Each tree contributes to the final\n",
        "prediction, with later trees typically having more influence because\n",
        "they’ve learned from more mistakes."
      ],
      "id": "f69796bf-fd33-46b0-ad3f-328c8bf18a4a"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Accuracy: 81.7%"
          ]
        }
      ],
      "source": [
        "# train gradient boosting model\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,  # how much each tree contributes\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# evaluate on test set\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "\n",
        "print(f\"Gradient Boosting Accuracy: {gb_accuracy:.1%}\")"
      ],
      "id": "gradient-boosting"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gradient boosting often achieves the best performance of these\n",
        "algorithms, particularly on tabular data. It’s the foundation of winning\n",
        "Kaggle solutions and production models at major tech companies. The\n",
        "sequential learning process allows it to capture complex patterns that\n",
        "other models miss. Like random forests, the trade-off is reduced\n",
        "interpretability compared to single trees.\n",
        "\n",
        "## Comparing Model Performance\n",
        "\n",
        "Different models learned different patterns from the same training data.\n",
        "Comparing their test set performance shows which patterns generalised\n",
        "best to unseen data."
      ],
      "id": "ae3d771c-5c16-4b57-bc55-4048788d2b97"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Model  Accuracy\n",
            "  Gradient Boosting  0.817164\n",
            "      Decision Tree  0.805970\n",
            "Logistic Regression  0.794776\n",
            "      Random Forest  0.787313"
          ]
        }
      ],
      "source": [
        "# create comparison dataframe\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting'],\n",
        "    'Accuracy': [lr_accuracy, tree_accuracy, rf_accuracy, gb_accuracy]\n",
        "})\n",
        "\n",
        "# sort by accuracy\n",
        "comparison = comparison.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(comparison.to_string(index=False))"
      ],
      "id": "model-comparison"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results demonstrate several principles. First, no single model\n",
        "dominates across all problems. Second, more complex models (random\n",
        "forest, gradient boosting) often outperform simpler ones, but not\n",
        "always. Third, even small accuracy differences can be meaningful\n",
        "depending on the application[1].\n",
        "\n",
        "We can also examine what each model learned by looking at feature\n",
        "importance. Tree-based models calculate feature importance based on how\n",
        "much each feature reduces impurity when used for splitting.\n",
        "\n",
        "[1] In healthcare applications, statistical significance doesn’t always\n",
        "equal clinical significance. A 2% improvement in accuracy might be\n",
        "meaningless for one use case and critically important for another.\n",
        "Domain knowledge determines whether model differences matter."
      ],
      "id": "cf26abac-d466-4539-8d65-578965d53941"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "# create dataframe for plotting\n",
        "feature_names = X_train.columns\n",
        "importance_data = pd.DataFrame({\n",
        "    'Feature': list(feature_names) * 3,\n",
        "    'Importance': list(tree_model.feature_importances_) + \n",
        "                  list(rf_model.feature_importances_) + \n",
        "                  list(gb_model.feature_importances_),\n",
        "    'Model': ['Decision Tree'] * len(feature_names) + \n",
        "             ['Random Forest'] * len(feature_names) + \n",
        "             ['Gradient Boosting'] * len(feature_names)\n",
        "})\n",
        "\n",
        "# create faceted plot\n",
        "g = sns.FacetGrid(importance_data, col='Model', height=4, aspect=0.8)\n",
        "g.map_dataframe(sns.barplot, y='Feature', x='Importance', order=feature_names)\n",
        "g.set_axis_labels('Importance', '')\n",
        "g.set_titles(col_template='{col_name}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-feature-importance"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The feature importance plots reveal what each model learned. All three\n",
        "tree-based models identified sex as the most important feature, which\n",
        "aligns with historical accounts of “women and children first” evacuation\n",
        "procedures. However, the models weight other features differently,\n",
        "showing they learned distinct patterns from the same data.\n",
        "\n",
        "## Overfitting and Model Complexity\n",
        "\n",
        "Model complexity is controlled through hyperparameters. For decision\n",
        "trees, the most important hyperparameter is `max_depth`, which limits\n",
        "how many sequential questions the tree can ask. Shallow trees underfit\n",
        "by not learning enough patterns. Deep trees overfit by learning noise in\n",
        "the training data."
      ],
      "id": "f1e09a4a-6a5e-40ee-9921-d6ba23fe3126"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "# test different tree depths\n",
        "depths = range(1, 16)\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for depth in depths:\n",
        "    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    tree.fit(X_train, y_train)\n",
        "    \n",
        "    train_scores.append(accuracy_score(y_train, tree.predict(X_train)))\n",
        "    test_scores.append(accuracy_score(y_test, tree.predict(X_test)))\n",
        "\n",
        "# create dataframe for plotting\n",
        "overfitting_data = pd.DataFrame({\n",
        "    'Tree Depth': list(depths) * 2,\n",
        "    'Accuracy': train_scores + test_scores,\n",
        "    'Dataset': ['Training Accuracy'] * len(depths) + ['Test Accuracy'] * len(depths)\n",
        "})\n",
        "\n",
        "# plot results\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=overfitting_data, x='Tree Depth', y='Accuracy', hue='Dataset', \n",
        "             marker='o', markersize=6)\n",
        "plt.title('Overfitting in Decision Trees')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-overfitting-demo"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plot demonstrates the classic overfitting pattern. As tree depth\n",
        "increases, training accuracy continues to improve because the tree\n",
        "learns increasingly specific rules about the training data. However,\n",
        "test accuracy peaks at moderate depth then declines. Beyond that peak,\n",
        "the tree is learning patterns that don’t generalise to new data.\n",
        "\n",
        "Finding the optimal complexity requires validation on held-out data.\n",
        "This principle applies to all models: logistic regression regularisation\n",
        "strength, random forest tree count and depth, gradient boosting learning\n",
        "rate and iterations. The goal is maximising generalisation, not training\n",
        "performance.\n",
        "\n",
        "## Summary\n",
        "\n",
        "Understanding how models learn transforms machine learning from a black\n",
        "box into a practical tool. Different algorithms approach learning\n",
        "differently: logistic regression finds linear boundaries, decision trees\n",
        "ask sequential questions, random forests combine many trees through\n",
        "voting, and gradient boosting trains trees that learn from previous\n",
        "mistakes.\n",
        "\n",
        "No algorithm works best in all situations. Simpler models like logistic\n",
        "regression and shallow decision trees are more interpretable but may\n",
        "miss complex patterns. Ensemble methods like random forests and gradient\n",
        "boosting often achieve better performance but sacrifice\n",
        "interpretability. The right choice depends on your data, your\n",
        "constraints, and whether you need to explain predictions to\n",
        "stakeholders.\n",
        "\n",
        "The key principles from this session apply broadly. Test multiple models\n",
        "and compare performance. Use validation data to detect overfitting.\n",
        "Examine feature importance to understand what models learned. Control\n",
        "complexity through hyperparameters. These practices form the foundation\n",
        "of effective model development.\n",
        "\n",
        "What we haven’t covered yet is how to systematically tune\n",
        "hyperparameters, how to handle imbalanced classes, or how to evaluate\n",
        "models using metrics beyond accuracy. We also haven’t explored feature\n",
        "engineering, which often matters more than algorithm choice. These\n",
        "topics build on the foundations we’ve established and will be covered in\n",
        "future sessions."
      ],
      "id": "a9345db4-8960-4a8d-bc02-0222ad50657b"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "C:.johnson-club.venv"
    }
  }
}