{
  "hash": "08f00880e48fe4d82111fae784f7682c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Generators\"\nformat:\n  html: default\n  ipynb: default\n---\n\n\n\n\n\n\nThis is a concept listed in the NHS's National Competency Framework as a requirement for intermediate Python Proficiency (SA21). In this tutorial, we are going to cover:\n\n-   What they are\n-   When it makes sense to use them and when not\n-   Example use cases:\n    -   **Data pipelines:** pre-processing large volumes of data *before* they reach your dataframes\n    -   **API calls:** loading large volumes of real-time data without overloading memory\n    -   **Modelling queuing problems and pathways:** a simple introduction to how generators are used in Discrete Event Simulation\n\n:::{.callout-warning}\n## Download\nWe very much recommend downloading the Jupyter Notebook so that you can run the code cells and see how the outputs change. You can do this by clicking on the \"Jupyter\" link under \"Other Formats\" over on the right-hand side below the page contents.\n:::\n\n## What are generators?\n\nSimply put, a generator is something that allows us to tackle _step by step_ a task that is either very large, open-ended or where we want to ensure that certain criteria are met before proceeding to the next step, without trying to complete the entire task in one go.\n\nWith tasks processing very large amounts of data, we run the risk of overloading the computer's memory.\n\nWith open-ended tasks, i.e. when the final number of items in our output is not known at the start, we might need to set up an infinite loop (`while True:`) instead of defining a specific range to iterate over, and generators allow us to use these in a controlled manner.\n\nIn programs where multiple iterative processes depend on the successful completion of each iteration of the others before proceeding, we can use generators. For example: complete step 1 of process A, return an output, complete step 1 of process B, return an output, and then pick up process A again at step 2, and so on. This is a bit more difficult to picture, but we will return to this when we have a look at Discrete Event Simulation.\n\n### How to create a generator function: the `yield` keyword.\n\nLet's now have a look at how to create a generator function and how they differ from ordinary functions.\n\nThe main difference is that instead of using the `return` keyword, generator functions use the `yield` keyword.\n\nConsider the following infinite loop function, courtesy of [Real Python](https://realpython.com/videos/understanding-generators/). The intention is to return numbers incrementally and indefinitely (`while True:` creates an infinite loop). However, `return` will only produce the first value in the sequence before ending the execution of the function. No matter how many times you run the cell below, it will only return \"0\".\n\n::: {#cell-infinite-function .cell execution_count=1}\n``` {.python .cell-code}\ndef infinite_sequence():\n    num = 0\n    while True:\n        return num\n        num += 1\n        \ninfinite_sequence()\n```\n\n::: {#infinite-function .cell-output .cell-output-display execution_count=1}\n```\n0\n```\n:::\n:::\n\n\nLet's now have a look at the same function, but this time replacing `return` with `yield`. Generators defined in this way create generator _objects_, which have to be assigned to a variable before they can be used.\n\n::: {#infinite-generator .cell execution_count=2}\n``` {.python .cell-code}\ndef infinite_sequence_gen():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ninfinite = infinite_sequence_gen()\n```\n:::\n\n\nA generator object is an _iterable_, that is to say an object type that can be iterated over item by item (another example of an iterable would be a _list_). This means that we can use Python's in-built `next` function to generate an output. Try running the following cell multiple times, as long as you like: it will keep incrementing the number up forever.\n\n::: {#cell-next-demo .cell execution_count=3}\n``` {.python .cell-code}\nnext(infinite)\n```\n\n::: {#next-demo .cell-output .cell-output-display execution_count=3}\n```\n0\n```\n:::\n:::\n\n\nGenerators return the next value in the sequence, remembering their place in that sequence. This means that they don't have to produce the entire output in one go, and instead can return one element at a time.\n\nIn contrast to normal functions, where once `return` is reached the function's execution is terminated, generators can contain multiple `yield` expressions and the generator will \"remember\" which one it got to in the previous iteration and move onto the next one. Run the next code cell once to set up the definition of the generator, then run the subsequent cell until you get to the end of the song.\n\n::: {#five-speckled-frogs .cell execution_count=4}\n``` {.python .cell-code}\nn_speckled_frogs = 5 # the number of speckled frogs on the speckled log.\n\ndef frog_song():\n    num = n_speckled_frogs\n    yield f'{num} little speckled frogs'\n    while True:\n        yield 'Sat on a speckled log'\n        yield 'Eating the most delicious bugs'\n        yield 'YUM YUM!'\n        yield 'One jumped into the pool'\n        yield 'Where it was nice and cool'\n        num -=1\n        if num == 0:\n            yield 'Then there were no more speckled frogs!'\n            break\n        elif num == 1:\n            yield 'Then there was 1 more speckled frog. Glub glub.'\n            yield f'{num} little speckled frog'\n        else:\n            yield f'Then there were {num} more speckled frogs. Glub glub.'\n            yield f'{num} little speckled frogs'\n\n\nfroggy_fun = frog_song()\n```\n:::\n\n\n::: {#cell-frogs-by-line .cell execution_count=5}\n``` {.python .cell-code}\n# Run this cell and sing along!\nnext(froggy_fun)\n```\n\n::: {#frogs-by-line .cell-output .cell-output-display execution_count=5}\n```\n'5 little speckled frogs'\n```\n:::\n:::\n\n\n### Generator comprehensions.\n\nIt is also possible to create generators in a similar way to list comprehensions. To make it a generator, write the comprehension in parentheses: ( ). It can then be iterated over in the same way as with a generator defined as a function, using `next()`.\n\n#### List comprehension:\n\n::: {#cell-list-comprehension .cell execution_count=6}\n``` {.python .cell-code}\nsquare_numbers_lc = [i**2 for i in range(5)]\n\nsquare_numbers_lc\n```\n\n::: {#list-comprehension .cell-output .cell-output-display execution_count=6}\n```\n[0, 1, 4, 9, 16]\n```\n:::\n:::\n\n\n#### Generator comprehension\n\n::: {#gen-comprehension .cell execution_count=7}\n``` {.python .cell-code}\nsquare_numbers_gc = (i**2 for i in range(5))\n```\n:::\n\n\nNow to iterate over it, run this cell until the generator is used up.\n\n::: {#cell-use-gen-comprehension .cell execution_count=8}\n``` {.python .cell-code}\nnext(square_numbers_gc)\n```\n\n::: {#use-gen-comprehension .cell-output .cell-output-display execution_count=8}\n```\n0\n```\n:::\n:::\n\n\n:::{.callout-note}\n## StopIteration\nDid you see a StopIteration error? This happens when a generator is forced to go beyond the end of any finite range it has been given to work with. There are ways to handle these errors and we will return to them.\n:::\n\n## When should I use generators?\n\nThe main trade-off that comes with using generators is **memory burden** versus **speed**. \n\nWe can create a quick comparison between the size and speed of generators that process information step-by-step versus approaches that process information all in one go by creating another pair of comprehensions, but this time encompassing a much greater range so that the differences are plainer to see.\n\nLet's define them first:\n\n::: {#comprehension-tests .cell execution_count=9}\n``` {.python .cell-code}\nlc_test = [i**2 for i in range(100000)]\n\ngc_test = (i**2 for i in range(100000))\n```\n:::\n\n\n### Memory burden\n\nFirst of all, how much memory does each of these take up?\n\n::: {#mem-test .cell execution_count=10}\n``` {.python .cell-code}\nimport sys # in-built Python library that can be used to access system information\n\nlist_size = sys.getsizeof(lc_test)\ngenerator_size = sys.getsizeof(gc_test)\n\nprint(f'The list takes up {list_size} bytes in memory')\nprint(f'The generator takes up {generator_size} bytes in memory')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe list takes up 800984 bytes in memory\nThe generator takes up 200 bytes in memory\n```\n:::\n:::\n\n\nThe list evidently takes up far more space in memory than the generator. That is because the list is being created all at once (all 99,999 intergers), whereas the generator is really just storing the _instructions_ for the comprehension, plus its current _state_ (i.e., which iteration it has got to).\n\nThis is a very trivial example, but imagine if you are working with hundreds of thousands of _rows_ of data. You would be dealing a much greater volume of data. Trying to process all of that data in one go would place a much greater burden on the computer's memory than processing it row by row.\n\nThe size of the generator remains roughly the same, despite the fact that we are dealing with much more data, but the size of the list grows with the volume of data.\n\n::: {#csv-comprehensions .cell execution_count=11}\n``` {.python .cell-code}\nfile = ('./data/ldahc.csv')\n\ncsv_list_comp = [row for row in open(file)]\ncsv_gen_comp = (row for row in open(file))\n\ncsv_list_comp_size = sys.getsizeof(csv_list_comp)\ncsv_gen_comp_size = sys.getsizeof(csv_gen_comp)\n\nprint(f'The size of the list comprehension is {csv_list_comp_size} bytes')\nprint(f'The size of the generator comprehension is {csv_gen_comp_size} bytes')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe size of the list comprehension is 800984 bytes\nThe size of the generator comprehension is 192 bytes\n```\n:::\n:::\n\n\n:::{.callout-tip}\n## Data source\nTo run this against the data yourself from a Jupyter Notebook, click [here](https://files.digital.nhs.uk/96/B5B8AE/learning-disabilities-health-check-scheme-eng-Jul-2025.csv) to start the download from the NHS Digital Publications page. Place the file in a `data` folder in the same directory as you Jupyter Notebook file. Be sure to rename the file or change the name in the filepath above.\n:::\n\n#### Should I use it to load .csv files into my `pandas` DataFrames, then?\n\nSince the `pandas` library has already been optimised to some degree[^Performance], you won't really gain much from using a generator to load data from a .csv directly into a Pandas dataframe. `pandas` already has a `chunksize=` keyword argument in its .read_csv() method for loading data from a .csv in batches. **However**, as we will see in the use cases section, you could still consider pre-processing your data _before it even reaches_ `pandas` (think about how `pandas` often makes a best guess about things like data types, which may not always be correct).\n\n[^Performance]:\n\nWhile `pandas` is reasonably good at handling large volumes of data, there are other options that are even more memory efficient. The `polars` library, for example, is much more memory-efficient. We tend to use `pandas` in our tutorials, because it is a much better developed, feature-rich library with a relatively straightforward syntax.\n\n### Speed\n\nHow do generators compare when it comes to speed? Let's return to our two comprehensions. For this we are going to use the in-built Python profiler library `cProfile`. Instead of passing a variable name to it, we need to give it an instruction as a text string.\n\n::: {#import-cprofile .cell execution_count=12}\n``` {.python .cell-code}\nimport cProfile\n```\n:::\n\n\nThe profiler will tell us how many function calls (operations) are being executed to complete the task and the time it has taken.\n\nFirst, the list comprehension:\n\n::: {#list-speed-test .cell execution_count=13}\n``` {.python .cell-code}\ncProfile.run('sum([i**2 for i in range(100000)])')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         4 function calls in 0.012 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.010    0.010    0.011    0.011 <string>:1(<module>)\n        1    0.000    0.000    0.012    0.012 {built-in method builtins.exec}\n        1    0.001    0.001    0.001    0.001 {built-in method builtins.sum}\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n\n\n```\n:::\n:::\n\n\nThen the generator comprehension:\n\n::: {#gen-speed-test .cell execution_count=14}\n``` {.python .cell-code}\ncProfile.run('sum((i**2 for i in range(100000)))')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         100005 function calls in 0.026 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n   100001    0.013    0.000    0.013    0.000 <string>:1(<genexpr>)\n        1    0.000    0.000    0.026    0.026 <string>:1(<module>)\n        1    0.000    0.000    0.026    0.026 {built-in method builtins.exec}\n        1    0.013    0.013    0.026    0.026 {built-in method builtins.sum}\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n\n\n```\n:::\n:::\n\n\nSo using the list comprehension is faster and is making far fewer function calls. This makes sense, because the generator comprehension is taking things step by step, whereas the list comprehension is doing things with fewer leaps and bounds.\n\nIn conclusion, generators are useful when the importance of staying within memory constraints outweighs the need for speed.\n\n## Example use cases\n\nWhat, then, are some practical uses for generators?\n\n### Data pipelines: pre-processing .csv data\n\nA little earlier, it was mentioned that there is not much to be gained from using a generator to read large amounts of data directly into a `pandas` dataframe. However, a generator could be used to perform some pre-processing _before_ the data gets fed into `pandas`. We may want to do this, if we want to ensure that we do not have mixed data types in a column, which would be interpreted by `pandas` as an `object`, which is a bit of a catch-all.\n\nFor example, we may receive a data file with a column that is meant to contain numeric data, but missing values have been filled with the text string \"NULL\". We may want to ensure that such \"missing-like\" values get removed.\n\nHere the generator function processes the data line by line to replace the \"NULL\" values with empty values and this is passed into a `pandas` DataFrame. We can then use `pandas` to treat the column as numeric without running into data type errors.\n\n::: {#cell-missing-head .cell execution_count=15}\n``` {.python .cell-code}\nimport pandas as pd\n\nfile = './data/missing-like.csv'\n\ndf = pd.read_csv(file)\n\ndf.head()\n```\n\n::: {#missing-head .cell-output .cell-output-display execution_count=15}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Category</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/04/2025</td>\n      <td>A</td>\n      <td>673.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/04/2025</td>\n      <td>B</td>\n      <td>663.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/05/2025</td>\n      <td>A</td>\n      <td>550.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/05/2025</td>\n      <td>B</td>\n      <td>565.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/06/2025</td>\n      <td>A</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#cell-preprocess-missing .cell execution_count=16}\n``` {.python .cell-code}\nimport csv\n\ndef preprocess_nulls(file):\n    with open(file, newline='', encoding='utf-8') as f:\n        reader = csv.reader(f)\n        headers = next(reader)  # column headers are the first iteration in the rows\n        yield headers           # yield this separately so that any preprocessing steps don't get applied.\n        for row in reader:\n            row[2] = row[2].replace('NULL','')\n            yield row\n\ndf = pd.DataFrame(preprocess_nulls(file=file))\ndf.columns = df.iloc[0] # set first row as column headings.\ndf = df.drop(0).reset_index(drop=True) # drop the row that contained the headings.\n\ndf\n```\n\n::: {#preprocess-missing .cell-output .cell-output-display execution_count=16}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>﻿Date</th>\n      <th>Category</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/04/2025</td>\n      <td>A</td>\n      <td>673</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/04/2025</td>\n      <td>B</td>\n      <td>663</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/05/2025</td>\n      <td>A</td>\n      <td>550</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/05/2025</td>\n      <td>B</td>\n      <td>565</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/06/2025</td>\n      <td>A</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>01/06/2025</td>\n      <td>B</td>\n      <td>849</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>01/07/2025</td>\n      <td>A</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>01/07/2025</td>\n      <td>B</td>\n      <td>336</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>01/08/2025</td>\n      <td>A</td>\n      <td>918</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>01/08/2025</td>\n      <td>B</td>\n      <td>963</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>01/09/2025</td>\n      <td>A</td>\n      <td>533</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>01/09/2025</td>\n      <td>B</td>\n      <td>306</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>01/10/2025</td>\n      <td>A</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>01/10/2025</td>\n      <td>B</td>\n      <td>298</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>01/11/2025</td>\n      <td>A</td>\n      <td>654</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>01/11/2025</td>\n      <td>B</td>\n      <td>672</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>01/12/2025</td>\n      <td>A</td>\n      <td>587</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>01/12/2025</td>\n      <td>B</td>\n      <td>404</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>01/01/2026</td>\n      <td>A</td>\n      <td>738</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>01/01/2026</td>\n      <td>B</td>\n      <td>295</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>01/02/2026</td>\n      <td>A</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>01/02/2026</td>\n      <td>B</td>\n      <td>900</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>01/03/2026</td>\n      <td>A</td>\n      <td>967</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>01/03/2026</td>\n      <td>B</td>\n      <td>370</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nOf course, this is just a demonstration. It would really come into its own when you are creating a pipeline that pre-processes multiple columns and 100,000+ rows.\n\n### API calls: loading large volumes of real-time data\n\nAnother, even more likely scenario for making use of generators for importing data is when accessing large amounts of real-time data via an API. With real-time data, it is not always known how much data will be coming through and this has the potential to overload memory if processed in one go.\n\nFor this example, we are going to access the Environment Agency's real-time [flood warning data](https://environment.data.gov.uk/flood-monitoring/doc/reference). We will just use a small example, flood alerts with a minimum severity of 3, but this could be applied to a much larger dataset.\n\n::: {#cell-api-generator .cell execution_count=17}\n``` {.python .cell-code}\nimport requests\n# import pandas as pd\n\ndef get_flood_alerts():\n    request_url = 'https://environment.data.gov.uk/flood-monitoring/id/floods?min-severity=3'\n    response = requests.get(request_url)\n    results_json = response.json()['items']\n    for json in results_json:\n        yield {\n            'id': json['@id'],\n            'description': json['description'],\n            'area_name': json['eaAreaName'],\n            'flood_area_id': json['floodAreaID'],\n            'is_tidal': json['isTidal'],\n            'severity': json['severity'],\n            'severity_level': json['severityLevel'],\n            'time_message_changed': json['timeMessageChanged'],\n            'time_raised': json['timeRaised'],\n            'time_severity_changed': json['timeSeverityChanged']\n        }\n\nalerts = pd.DataFrame(get_flood_alerts())\n\nalerts\n```\n\n::: {#api-generator .cell-output .cell-output-display execution_count=17}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n      <th>area_name</th>\n      <th>flood_area_id</th>\n      <th>is_tidal</th>\n      <th>severity</th>\n      <th>severity_level</th>\n      <th>time_message_changed</th>\n      <th>time_raised</th>\n      <th>time_severity_changed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n      <td>Severn Vyrnwy confluence</td>\n      <td>West Midlands</td>\n      <td>031WAF114</td>\n      <td>False</td>\n      <td>Flood alert</td>\n      <td>3</td>\n      <td>2025-09-22T08:58:00</td>\n      <td>2025-09-22T08:58:26</td>\n      <td>2025-09-20T14:07:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n      <td>River Dee catchment in England from Whitchurch...</td>\n      <td>Greater Manchester, Merseyside and Cheshire</td>\n      <td>013WAFDEE</td>\n      <td>False</td>\n      <td>Flood alert</td>\n      <td>3</td>\n      <td>2025-09-22T10:04:00</td>\n      <td>2025-09-22T10:04:42</td>\n      <td>2025-09-20T17:19:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n      <td>Upper River Ouse</td>\n      <td>Yorkshire</td>\n      <td>122WAF946</td>\n      <td>False</td>\n      <td>Flood alert</td>\n      <td>3</td>\n      <td>2025-09-22T08:09:00</td>\n      <td>2025-09-22T08:09:47</td>\n      <td>2025-09-20T20:17:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n      <td>River Severn in Shropshire</td>\n      <td>West Midlands</td>\n      <td>031WAF103</td>\n      <td>False</td>\n      <td>Flood alert</td>\n      <td>3</td>\n      <td>2025-09-22T08:58:00</td>\n      <td>2025-09-22T08:58:37</td>\n      <td>2025-09-21T08:57:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n      <td>Rivers Brathay, Rothay and Winster</td>\n      <td>Cumbria and Lancashire</td>\n      <td>011WAFBR</td>\n      <td>False</td>\n      <td>Flood alert</td>\n      <td>3</td>\n      <td>2025-09-22T09:45:00</td>\n      <td>2025-09-22T09:46:00</td>\n      <td>2025-09-15T14:31:00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n      <td>Upper River Derwent, Stonethwaite Beck and Der...</td>\n      <td>Cumbria and Lancashire</td>\n      <td>011WAFDW</td>\n      <td>False</td>\n      <td>Flood alert</td>\n      <td>3</td>\n      <td>2025-09-22T09:46:00</td>\n      <td>2025-09-22T09:46:13</td>\n      <td>2025-09-15T07:25:00</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n      <td>River Ouse at York - riverside properties</td>\n      <td>Yorkshire</td>\n      <td>122FWF710</td>\n      <td>False</td>\n      <td>Flood warning</td>\n      <td>2</td>\n      <td>2025-09-22T08:09:00</td>\n      <td>2025-09-22T08:09:54</td>\n      <td>2025-09-21T19:02:00</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n      <td>Keswick Campsite</td>\n      <td>Cumbria and Lancashire</td>\n      <td>011FWFNC6KC</td>\n      <td>False</td>\n      <td>Flood warning</td>\n      <td>2</td>\n      <td>2025-09-22T09:45:00</td>\n      <td>2025-09-22T09:46:19</td>\n      <td>2025-09-15T16:38:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n\\\nThe `for` loop in the non-generator version would look like this:\n\n::: {#api-non-generator .cell execution_count=18}\n``` {.python .cell-code}\n    alerts = [{\n        'id' : json['@id'],\n        # etc.\n    } for json in results_json]\n    return alerts\n```\n:::\n\n\nUsing a generator is particularly useful when the data is _paginated_, that is to say when a huge volume of data (millions of rows) is made available via an API endpoint across multiple pages, rather than all in one block.\n\n`https://api.example.com/data?page=1`\\\n`https://api.example.com/data?page=2`\n\nIterating over each page _without_ using a generator would return everything in one huge list sitting in memory. Here is a generic example to illustrate:\n\n::: {#paginated-non-generator .cell execution_count=19}\n``` {.python .cell-code}\ndef get_all_data():\n    data = []\n    page = 1\n    while True:\n        resp = requests.get(\"https://api.example.com/data\", params={\"page\": page}).json()\n        if not resp[\"results\"]:\n            break\n        data.extend(resp[\"results\"])    \n        page += 1\n    return data\n```\n:::\n\n\n_With_ a generator, you can _stream_ the data, processing the items as they arrive.\n\n::: {#paginated-generator .cell execution_count=20}\n``` {.python .cell-code}\ndef get_all_data_gen():\n    page = 1\n    while True:\n        resp = requests.get(\"https://api.example.com/data\", params={\"page\": page}).json()\n        results = resp[\"results\"]\n        if not results:\n            break\n        for item in results:\n            yield item\n        page += 1\n\nfor record in get_all_data_gen():\n    process(record)\n```\n:::\n\n\n### Modelling queueing problems and pathways: Discrete Event Simulation\n\nDiscrete Event Simulation (DES) is a fantastic technique for modelling systems where entities move along a pathway (or pathways) and those entities queue at different points on a given pathway until resources become available to perform some kind of task with those entities. One typical use case is modelling manufacturing production lines, where an analyst might use DES to determine whether there are any bottlenecks in the process, meaning that downstream processes are held up, or conversely where cost savings could be made by removing excess resources that do not contribute enough of a productivity gain to justify their deployment. In a healthcare setting, DES models can be used to model wards or clinics to understand how patients flow through, and different \"what-if\" scenarios can be tested out (what if we had one more nurse on the ward; what if we were able to reduce consultation times by five minutes), all without risking harm to patients. We can use them to model branching pathways (e.g. as a result of triage assessments) and to model resources in terms of staff and \"stuff\", that is to say things like beds and cubicles. \n\nIn Python, the package that is typically used for building DES models is `simpy`. This is used to create an `Environment` object which co-ordinates and keeps track of the various resources, processes and the entities subject to those processes.\n\nGenerators come into play when we want to simulate patient arrivals. Imagine we have a pool of patients booked in to attend a clinic within a 2-hour window. It is very unlikely that all of the patients would arrive at exactly the same time at the beginning of the time window. In a real-life situation, we would expect people to arrive at different times (even if it was stipulated that everyone had to arrive punctually, there would still be people who get held up trying to get to the clinic and arrive late). Generators allow us to simulate this natual _variability_. The same applies to the processes at each step in the pathway: we use the `yield` keyword to release a resource after the simulated amount of time for the process has elapsed. We can string together processes that depend on each other and evaluate the impact of changes made to different parts of the system.\n\nThere is a lot more to Discrete Event Simulation, but we will return to it when we cover the topic in its own session.\n\nNow let's have a look at a simple model to see generators in action in this context.\n\n#### Setting the scene: A flu jab clinic\n\nA commissioner wants to see how many receptionists and nurses would be required to vaccinate a target number of patients during a clinic on a given day. They want to know how long the clinic would have to run for to see all the patients as well as the the average and maximum waiting times.\n\n![Our simple vaccination clinic](images/model_diagram.png)\n\n#### Clinic parameters\n\nBelow are the parameters for our clinic. Try changing them to see what effect that has on the outcome. Remember that you want to try to balance things at each stage of the process to minimise queueing times. Do you need more nurses or more receptionists? What is the best ratio? Can you cut the total clinic time and still see the patients? How far can you increase the target number of patients seen?\n\nMost of these parameters should be self-explanatory, but the one you may not be familiar with is \"INTERARRIVAL_TIME\". The interarrival time is the amount of time between patients arriving at the clinic and joining the queue for registration with the receptionist. The _average_ interarrival time would then be used to inform the model. \n\n::: {#des-parameters .cell execution_count=21}\n``` {.python .cell-code}\nTARGET_PATIENTS_SEEN = 50\nRECEPTIONISTS_AVAILABLE = 1\nVACCINATION_NURSES_AVAILABLE = 4\nMAX_CLINIC_TIME = 450\nAVG_REGISTRATION_TIME = 10\nAVG_VACCINATION_TIME = 5\nINTERARRIVAL_TIME = 3         \n```\n:::\n\n\n:::{.callout-note}\n## Data collection\nIf you were modelling a healthcare system with Discrete Event Simulation in real life, it is likely that you would have to collect some of this data yourself by sitting in on real clinics and/or with the help of administrative and medical staff. For example, it would involve using a stopwatch to record patient interarrival times before finding the average.\n:::\n\n#### The model itself\n\nThe model has been split into sections to make it easier to understand. We have also stuck to a functional programming structure to keep things simple, given that we want to keep the focus on the generator functions. Discrete Event Simulations are normally great examples of object-oriented programming, because it is suited to modelling entities interacting with each other.\n\n##### Creating generator functions to model the patient movements\n\nWe won't go into all the details; we can go over those when we do a session on Discrete Event Simulation. The main things to understand are:\n\n- The `patient_arrival_generator()` function will generate as many patients as defined above in the `TARGET_PATIENTS_SEEN` parameter. (If we weren't interested in a set number of patients, we could create an infinite loop with `while True`)\n- After each patient has arrived at the clinic, an interarrival time `t` is randomly sampled. It is based on `INTERARRIVAL_TIME` being the average of those sampled values.\n- Generation of patients is paused until that time has passed, and then the next patient in the sequence gets generated.\n\n- The `activity_generator()` function is split into two. Each step in the process (registration, getting vaccinated) is contained within a `with` block. When a `with` block ends, the resource is automatically freed up.\n- `env.now` is used to collect timestamps at different points to allow us to calculate the length of time spent in each queue.\n- A random amount of time is sampled to represent the amount of time each patient spends at registration and getting vaccinated, and therefore _how much time they are occupying those resources_.\n- The `.request()` method creates an event object representing a request for one unit of capacity of the resource (1 receptionist, 1 nurse). If capacity is available, the request can be fulfilled and the process continues; if not, the process is frozen for that patient (i.e. the patient joins the queue for the resource) until SimPy is able to give access to the resource and the process can continue.\n- The fact that generators with `yield` are being used enables us to move on to the next step in a sequence for each individual patient.\n\n:::{.callout-tip}\n## Queueing outputs\nTo see the printout of the times patients joined queues and started each process, un-comment lines **42, 45, 57, 66, 69** where you see the `print()` statements. They have been commented out for display on the web page since the output is quite long!\n:::\n\n::: {#des-generators .cell execution_count=22}\n``` {.python .cell-code code-line-numbers=\"true\"}\nimport simpy\nimport random\n\n# Arrivals generator function\n\ndef patient_arrival_generator(env, INTERARRIVAL_TIME, AVG_REGISTRATION_TIME, AVG_VACCINATION_TIME,receptionist,nurse):\n    patient_id = 0\n\n    for patient_id in range(int(TARGET_PATIENTS_SEEN)):\n        # create an instance of the activity generator\n        patient_act = activity_generator(env,AVG_REGISTRATION_TIME,AVG_VACCINATION_TIME,receptionist,nurse,patient_id)\n\n        # run the activity generator for this patient\n        env.process(patient_act)\n\n        # sample the time until next patient\n        t = random.expovariate(1.0 / INTERARRIVAL_TIME)\n\n        # freeze the arrival generator until that time has passed\n        yield env.timeout(t)\n\n        # increment the patient ID number for the next patient\n        patient_id +=1\n\n# Activity generator function\n\ndef activity_generator(env, AVG_REGISTRATION_TIME, AVG_VACCINATION_TIME, receptionist, nurse, patient_id):\n\n    # reference some global variables, i.e. ones that exist outside of this function.\n    # we want to pass the waiting times out to these buckets so that we can use them later.\n    global list_of_queueing_times_registration\n    global list_of_queueing_times_nurse\n    \n    # record the time a patient arrives and enters the queue for registration\n    time_entered_queue_for_registration = env.now\n\n    with receptionist.request() as req:\n        # freeze until the request can be met, i.e. when a receptionist is available.\n        yield req\n\n        time_left_queue_for_registration = env.now\n        # print(f'Patient {patient_id} left the queue for the receptionist at {time_left_queue_for_registration:.2f}')\n\n        time_in_queue_for_registration = time_left_queue_for_registration - time_entered_queue_for_registration\n        # print(f'Patient {patient_id} queued for registration for {time_in_queue_for_registration:.2f} minutes')\n\n        # add the waiting time to the global list\n        list_of_queueing_times_registration.append(time_in_queue_for_registration)\n\n        # sampled time spent with with receptionist during registration\n        sampled_registration_time = random.expovariate(1.0 / AVG_REGISTRATION_TIME)\n\n        # freeze the activity generator until that time has passed\n        yield env.timeout(sampled_registration_time)\n\n    time_entered_queue_for_nurse = env.now\n    # print(f'Patient {patient_id} joined the queue for the nurse at {time_entered_queue_for_nurse:.2f}')\n\n    # request a nurse\n    with nurse.request() as req:\n        # freeze until the request can be met, i.e. when a nurse is available.\n        yield req\n\n        # calculate the time the patient was queuing\n        time_left_queue_for_nurse = env.now\n        # print(f'Patient {patient_id} left the queue for the nurse at {time_left_queue_for_nurse:.2f}')\n\n        time_in_queue_for_nurse = time_left_queue_for_nurse - time_entered_queue_for_nurse\n        # print(f'Patient {patient_id} queued for the nurse for {time_in_queue_for_nurse:.2f} minutes')\n\n        # add the waiting time to the global list\n        list_of_queueing_times_nurse.append(time_in_queue_for_nurse)\n\n        # sampled time spent with nurse receiving the vaccination\n        sampled_vaccination_time = random.expovariate(1.0 / AVG_VACCINATION_TIME)\n\n        # freeze the activity generator until that time has passed\n        yield env.timeout(sampled_vaccination_time)\n```\n:::\n\n\n##### Setting up the SimPy simulation environment\n\nIn this section, we create an environment inside which the processes take place, and define `nurse` and `receptionist` as SimPy `Resource` objects. We also set up our lists that will log the queueing times so that the `max` and `mean` of each can be calculated.\n\n::: {#des-setup .cell execution_count=23}\n``` {.python .cell-code}\n# instantiate SimPy simulation environment\nenv = simpy.Environment()\n\n# set up resources:\n# Nurses and receptionists inhabit our simulated clinic environment \"env\".\n# \"Capacity\" relates to the number of units of each resource.\nnurse = simpy.Resource(env, capacity=VACCINATION_NURSES_AVAILABLE)\nreceptionist = simpy.Resource(env, capacity=RECEPTIONISTS_AVAILABLE)\n\n# initiate lists to collect waiting times\nlist_of_queueing_times_registration = []\nlist_of_queueing_times_nurse = []\n```\n:::\n\n\n:::{.callout-note}\n## Global variables\nDo you recall seeing the waiting lists referred to as `global` variables within the `activity_generator()` function? Ordinarily, variables defined inside functions cannot be accessed from outside them. Using the `global` keyword means that values assigned to these variables can be accessed by other parts of the program.\n:::\n\n##### Running the simulation\n\nWe set off the patient arrivals generator function and tell SimPy to run the simulation for the number of time units defined in our clinic parameters. In this example, we are trying to see what resources are needed to treat the target number of patients within a fixed time period. However, you could also run the simulation without using the `until` argument and it will run until all of the patients have been treated.\n\nWas the vaccination team able to get through the target number of patients within the permitted clinic time?\n\n::: {#run-des .cell execution_count=24}\n``` {.python .cell-code}\n# start the arrivals generator\nenv.process(patient_arrival_generator(env, INTERARRIVAL_TIME, AVG_REGISTRATION_TIME, AVG_VACCINATION_TIME,receptionist,nurse))\n\n# run the simulation for TOTAL_CLINIC_TIME units of time (\"minutes\")\nenv.run(until=MAX_CLINIC_TIME) \n```\n:::\n\n\n##### Calculate some metrics relating to the queueing times\n\nNow we can do something with those global variables to derive the metrics we can use to evaluate the configuration of our vaccination clinic. Would you say that the waiting times for both stages of the clinic are acceptable?\n\n::: {#des-metrics .cell execution_count=25}\n``` {.python .cell-code}\nfrom statistics import mean\n\n# calculate and print mean/max queueing times for registration\nmean_queue_time_registration = mean(list_of_queueing_times_registration)\nmax_queue_time_registration = max(list_of_queueing_times_registration)\nprint(f\"Mean queuing time for registration (mins) : {mean_queue_time_registration:.2f}\")\nprint(f\"Max queuing time for registration (mins) : {max_queue_time_registration:.2f}\")\n\n# calculate and print mean/max queueing time for the nurses\nmean_queue_time_nurse = mean(list_of_queueing_times_nurse)\nmax_queue_time_nurse = max(list_of_queueing_times_nurse)\nprint(f\"Mean queuing time for the nurses (mins) : {mean_queue_time_nurse:.2f}\")\nprint(f\"Max queuing time for the nurses (mins) : {max_queue_time_nurse:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean queuing time for registration (mins) : 136.36\nMax queuing time for registration (mins) : 265.88\nMean queuing time for the nurses (mins) : 0.00\nMax queuing time for the nurses (mins) : 0.00\n```\n:::\n:::\n\n\n## Exercises\n\n1. What is the difference between using the `return` keyword and the `yield` keyword?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\nWhen the `return` keyword is reached, the execution of the function is terminated, so it only produces one output. That often means that the entirety of an iterable gets produced, or it can mean that only the first item in the iterable gets produced before the function ends (depending on how you have constructed your function).\n\nWith the `yield` keyword, each item in the iterable can be produced, item-by-item, over multiple function calls until the iterable is used up.\n\n:::\n\n2. What are the differences between writing a list comprehension and a generator comprehension? How about returning values from each of those?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\nA list comprehension is written in square brackets e.g. `[n**2 for n in numbers]`\n\nA generator comprehension is written in parentheses e.g. `(n**2 for n in numbers)`\n\nGenerator comprehensions also need to be iterated over in some way. The following code will just return the address of the generator object in memory.\n\n::: {#a2 .cell execution_count=26}\n``` {.python .cell-code}\nsquares = (n**2 for n in numbers)\nprint(squares)\n```\n:::\n\n\nYou need to use some kind of function that will iterate over the values, e.g. `next(squares)` or `for i in squares:...`\n\n:::\n\n3. Can you fix the following generator function so that it will alternate between counting numbers and returning \"Mississippi\"?\n\n::: {#q-mississippi-1 .cell execution_count=27}\n``` {.python .cell-code}\ndef counting_seconds():\n    num = 1\n    yield num\n    while True:\n        yield 'Mississippi'\n        num += 1\n\nseconds = counting_seconds()\n```\n:::\n\n\n::: {#cell-q-mississippi-2 .cell execution_count=28}\n``` {.python .cell-code}\nnext(seconds)\n```\n\n::: {#q-mississippi-2 .cell-output .cell-output-display execution_count=24}\n```\n1\n```\n:::\n:::\n\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#a-mississippi-1 .cell execution_count=29}\n``` {.python .cell-code}\ndef counting_seconds():\n    num = 1\n    yield num\n    while True:\n        yield 'Mississippi'\n        num += 1\n        yield num\n\nseconds = counting_seconds()\n```\n:::\n\n\n::: {#a-mississippi-2 .cell execution_count=30}\n``` {.python .cell-code}\nnext(seconds)\n```\n:::\n\n\n:::\n\n4. Why are generators good for working with _paginated_ data via API endpoints?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\nGenerators can return potentially vast amounts of data page by page as needed, rather than loading the entirety in one go.\n\n:::\n\n5. If we wanted to see the _total_ number of patients who could be vaccinated in our example clinic, without changing the resources or the clinic length, how would we modify our patient arrivals generator function?\n\n::: {#q5 .cell execution_count=31}\n``` {.python .cell-code}\ndef patient_arrival_generator(env, INTERARRIVAL_TIME, AVG_REGISTRATION_TIME, AVG_VACCINATION_TIME,receptionist,nurse):\n    patient_id = 0\n\n    for patient_id in range(int(TARGET_PATIENTS_SEEN)):\n\n        patient_act = activity_generator(env,AVG_REGISTRATION_TIME,AVG_VACCINATION_TIME,receptionist,nurse,patient_id)\n\n        env.process(patient_act)\n\n        t = random.expovariate(1.0 / INTERARRIVAL_TIME)\n\n        yield env.timeout(t)\n\n        patient_id +=1\n```\n:::\n\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#a5 .cell execution_count=32}\n``` {.python .cell-code}\ndef patient_arrival_generator(env, INTERARRIVAL_TIME, AVG_REGISTRATION_TIME, AVG_VACCINATION_TIME,receptionist,nurse):\n    patient_id = 0\n\n    while True:\n\n        patient_act = activity_generator(env,AVG_REGISTRATION_TIME,AVG_VACCINATION_TIME,receptionist,nurse,patient_id)\n\n        env.process(patient_act)\n\n        t = random.expovariate(1.0 / INTERARRIVAL_TIME)\n\n        yield env.timeout(t)\n\n        patient_id +=1\n```\n:::\n\n\n`while True` creates an infinite loop that will continue to generate patients until the the time set for the length of the simulation has elapsed (i.e. the value passed to `env.run(until=...)`)\n\n:::\n\n---\njupyter:\n  kernelspec:\n    display_name: Python 3 (ipykernel)\n    language: python\n    name: python3\n    path: 'C:\\Users\\edward.chick\\OneDrive - NHS\\Documents\\my_dev\\code_club_webpage\\.venv\\share\\jupyter\\kernels\\python3'\n  language_info:\n    codemirror_mode:\n      name: ipython\n      version: 3\n    file_extension: .py\n    mimetype: text/x-python\n    name: python\n    nbconvert_exporter: python\n    pygments_lexer: ipython3\n    version: 3.12.7\n---\n",
    "supporting": [
      "index_files\\figure-ipynb"
    ],
    "filters": []
  }
}