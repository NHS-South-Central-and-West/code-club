{
  "hash": "d06e23cfaef07f13bf453c07b4eaac89",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Comparison - Thief of Joy?\"\nformat:\n  html: default\n  ipynb: default\n---\n\n\n\n\n\n\nThis notebook walks through the process of comparing samples, demonstrating **why** comparisons matter and how we go about them, applying these ideas using data on fatal car crashes in the U.S.\n\n**We'll cover:**\n- Why we compare groups in data analysis\n- How samples differ from populations\n- How to visualize and interpret group differences\n- How to assess whether a difference is meaningful (statistically)\n\n## Why Compare?\n\n**Motivating example:**\nImagine an online store tests two versions of its homepage: Version A and Version B. After a week, it finds Version B users spent more money on average.\n- Is that difference real, or just random chance?\n- Could we expect the same pattern next week?\n\n**Takeaway:** Comparing samples helps us decide whether patterns in our data are **meaningful** or simply **random variation**. It’s a core building block before modelling relationships.\n\n**Questions:**\n\n- Can you think of any healthcare-related comparisons similar to the motivating example?\n- How do you currently decide whether the difference you observe in your data is real or occurred by chance?\n- Why is it important to know if differences observed in data occurred by chance?\n\n### Population vs. Sample\n\n![Source: [Martijn Wieling](https://www.let.rug.nl/wieling/Statistiek-I/HC2/)](images/popsample.png)\n\n**Key concepts:**\n\n- **Population**: the full group we're interested in (e.g. all customers, all days from 1992–2016)\n- **Sample**: a subset we actually observe or focus on (e.g. one week's users, a set of 4/20 days)\n\nIf we had access to the population, comparisons would be straightforward. But we usually don’t—so we have to take a sample of the population and make inferences about the population from our sample. That means dealing with uncertainty, variation, and potential bias.\n\nTo compare groups responsibly, we need to consider how sampling affects what we observe, and how it may limit our comparisons. The sample is a small snapshot of the population, and there are lots of reasons why a sample might not be representative of the wider population.\n\n::: {#population-vs-sample .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport random\n\n# simulate drawing 10 cards from a standard deck\ndeck = list(range(1, 14)) * 4\n\n# draw two random samples of ten cards\nsample1 = random.sample(deck, 5)\nsample2 = random.sample(deck, 5)\n\n# compute sample means\nmean1 = np.mean(sample1)\nmean2 = np.mean(sample2)\n\n# compute population mean\npopulation_mean = np.mean(deck)\n\nprint(\"Sample means:\", mean1, mean2)\nprint(\"Population mean:\", population_mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSample means: 7.0 6.4\nPopulation mean: 7.0\n```\n:::\n:::\n\n\n**Question:** Why are the sample means different? And why are they different from the population mean?\n\n**Takeaway:** Even if the process is fair, individual samples vary. This is a core challenge of inference.\n\nWe rely on well-designed comparisons to manage these uncertainties, using statistical tools that help us determine whether sample-level observations likely reflect real population-level differences.\n\n## Comparing Car Crash Fatalities - High or Not?\n\nNow we can apply this logic to a real-world dataset. We will use a dataset that records the daily count of fatal U.S. car crashes from 1992–2016, taken from a [study into the effects of the annual cannabis holiday, 4/20, on fatal car accidents](https://injuryprevention.bmj.com/content/25/5/433). Previous research has concluded that fatalities are higher on 4/20, suggesting that the holiday is the cause of the increase.\n\nWe are using a dataset, provided by [Tidy Tuesday](https://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-04-22/readme.md), which includes an indicator for April 20th (4/20). We will investigate whether 4/20 sees more crashes than expected.\n\n### Import & Process Data\n\n::: {#cell-import-data .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\n\n# load data\nraw_420 = pd.read_csv('data/daily_accidents_420.csv', parse_dates=['date'])\n\n# inspect data\nraw_420.head()\n```\n\n::: {#import-data .cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>e420</th>\n      <th>fatalities_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1992-01-01</td>\n      <td>False</td>\n      <td>144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1992-01-02</td>\n      <td>False</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992-01-07</td>\n      <td>False</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1992-01-12</td>\n      <td>False</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1992-01-03</td>\n      <td>False</td>\n      <td>182</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#cell-count-missing-values .cell execution_count=3}\n``` {.python .cell-code}\n# count missing values\nraw_420.isna().sum()\n```\n\n::: {#count-missing-values .cell-output .cell-output-display execution_count=3}\n```\ndate                 0\ne420                13\nfatalities_count     0\ndtype: int64\n```\n:::\n:::\n\n\n::: {#cell-inspect-missing-values .cell execution_count=4}\n``` {.python .cell-code}\n# inspect missing values\nraw_420[raw_420['e420'].isna()]\n```\n\n::: {#inspect-missing-values .cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>e420</th>\n      <th>fatalities_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1099</th>\n      <td>1994-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1428</th>\n      <td>1995-04-20</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1834</th>\n      <td>1996-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2201</th>\n      <td>1997-04-20</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3301</th>\n      <td>2000-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4400</th>\n      <td>2003-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5485</th>\n      <td>2006-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5867</th>\n      <td>2007-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6234</th>\n      <td>2008-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6968</th>\n      <td>2010-04-20</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7702</th>\n      <td>2012-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8393</th>\n      <td>2014-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8802</th>\n      <td>2015-04-20</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#transform-data .cell execution_count=5}\n``` {.python .cell-code}\ndf = (\n    raw_420\n    # convert e420 to boolean and rename\n    .assign(is_420=raw_420['e420'].astype(bool))\n    # drop missing values\n    .dropna()\n    # create boolean where TRUE if date is 07/04\n    .assign(is_4th_july=(raw_420['date'].dt.month == 7) & (raw_420['date'].dt.day == 4))\n    # select relevant columns\n    [['date', 'is_420', 'is_4th_july', 'fatalities_count']]\n)\n```\n:::\n\n\n::: {#cell-check-data .cell execution_count=6}\n``` {.python .cell-code}\ndf.head()\n```\n\n::: {#check-data .cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>is_420</th>\n      <th>is_4th_july</th>\n      <th>fatalities_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1992-01-01</td>\n      <td>False</td>\n      <td>False</td>\n      <td>144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1992-01-02</td>\n      <td>False</td>\n      <td>False</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992-01-07</td>\n      <td>False</td>\n      <td>False</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1992-01-12</td>\n      <td>False</td>\n      <td>False</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1992-01-03</td>\n      <td>False</td>\n      <td>False</td>\n      <td>182</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Visual Comparisons\n\n::: {#cell-group-means .cell execution_count=7}\n``` {.python .cell-code}\ndf.groupby('is_420')['fatalities_count'].mean()\n```\n\n::: {#group-means .cell-output .cell-output-display execution_count=7}\n```\nis_420\nFalse    144.92477\nTrue      54.60000\nName: fatalities_count, dtype: float64\n```\n:::\n:::\n\n\n::: {#cell-time-series .cell execution_count=8}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(15, 8))\n\n# line plot of daily fatalities\nsns.lineplot(data=df, x='date', y='fatalities_count', color=\"#0081a7\", linewidth=0.5)\n\n# scatter plot for 4/20 days, filter using .loc to avoid NA issues\nsns.scatterplot(\n    data=df.loc[df['is_420'] == True],\n    x='date', y='fatalities_count',\n    color='#ef233c', label='4/20'\n    )\n\nplt.title('Daily Fatalities (1992-2016)')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/time-series-output-1.png){#time-series}\n:::\n:::\n\n\n::: {#cell-raw-distributions .cell execution_count=9}\n``` {.python .cell-code}\nplt.figure(figsize=(12, 6))\n\n# define colour palette\ncustom_palette = {False: '#0081a7', True: '#ef233c'}\n\n# histogram\nplt.subplot(1, 2, 1)\nsns.histplot(data=df, x='fatalities_count', hue='is_420', kde=True, palette=custom_palette)\nplt.title('Histogram')\n\n# boxplot\nplt.subplot(1, 2, 2)\nsns.boxplot(data=df, x='is_420', y='fatalities_count', hue='is_420', palette=custom_palette, legend=False)\nplt.xticks([0, 1], ['Other days', '4/20'])\nplt.title('Boxplot')\n\n# figure title\nplt.suptitle('Distribution of Fatalities', fontsize=14)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/raw-distributions-output-1.png){#raw-distributions}\n:::\n:::\n\n\nThe imbalance between 4/20 and other days in the year makes it impossible to really see what is going on in our histogram. We can normalise the two distributions such that the total area of both equals one. This preserves their shape but accounts for the count imbalance between the two.\n\nSee the Seaborn documentation for more information: https://seaborn.pydata.org/generated/seaborn.histplot.html\n\nWe can also replace the boxplot with a violin plot, which will give us a little more intuition for the shape of the two groups.\n\n::: {#cell-normalised-distributions .cell execution_count=10}\n``` {.python .cell-code}\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nsns.histplot(data=df, x='fatalities_count', hue='is_420', palette=custom_palette, kde=True, stat='density', common_norm=False)\nplt.title('Density-Normalised Histogram')\n\nplt.subplot(1, 2, 2)\nsns.violinplot(data=df, x='is_420', y='fatalities_count', inner='quart', hue='is_420', palette=custom_palette, legend=False)\nplt.xticks([0, 1], ['Other days', '4/20'])\nplt.title('Violin Plot')\n\nplt.suptitle('Distribution of Fatalities', fontsize=14)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/normalised-distributions-output-1.png){#normalised-distributions}\n:::\n:::\n\n\n**Question:** What do you notice about the distribution (centre, spread, outliers, etc.)?\n\n### Testing Comparisons\n\nVisual and descriptive comparisons are limited because they only tell us whether there is a difference. They don't help us infer whether those difference occurred due to random variation or if there is something real going on. Visual comparisons cannot tell us whether we should expect to observe the differences we see in our samples in the population.\n\nThat's where statistical tests come in! Once we’ve visualized potential differences, we can test whether they’re statistically significant, using a two-sample *t*-test.\n\nA *t*-test is a statistical test used to compare the means of two groups to determine if the difference between them is statistically significant. It takes into account:\n\n- The size of the difference between the two group means.\n- The variability (spread) of the data within each group.\n- The sample size (number of observations in each group).\n\nThe *t*-test calculates a p-value, which is the probability of observing a difference as extreme or more extreme than the one found, assuming there is no true difference between the groups in the population (i.e., the null hypothesis is true). If the p-value is small enough (below a threshold like 0.05), you reject the null hypothesis and conclude that the difference between the groups is likely real and not due to random chance.\n\n\n\n\n\n\n{{< video https://youtu.be/0oc49DyA3hU?si=0x24ncYVQKbJP2sY >}}\n\n::: {#t-test .cell execution_count=11}\n``` {.python .cell-code}\nfrom scipy.stats import ttest_ind\n\n# create our samples for comparison\ngroup_420 = df.loc[df.is_420, 'fatalities_count']\ngroup_other = df.loc[~df.is_420, 'fatalities_count']\n\n# calculate t-statistic and p-value\nt_stat, p_val = ttest_ind(group_420, group_other, equal_var=False)\nprint(f\"t-statistic = {t_stat:.3f}, p-value = {p_val:.3f}\")\n\n# calculate mean difference\nmean_diff = group_420.mean() - group_other.mean()\n# calculate standard errors\nse_diff = np.sqrt(\n    group_420.var(ddof=1)/len(group_420)\n    + group_other.var(ddof=1)/len(group_other)\n    )\n\n# ci_lower = mean_diff - 1.96 * se_diff\n# ci_upper = mean_diff + 1.96 * se_diff\n# print(f\"Mean difference = {mean_diff:.2f} (95% CI: {ci_lower:.2f}, {ci_upper:.2f})\")\n\nprint(f\"Mean difference = {mean_diff:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nt-statistic = -29.369, p-value = 0.000\nMean difference = -90.32\n```\n:::\n:::\n\n\n**Interpretation:**\n\n- If *p* < 0.05, we reject the null that there is no true difference between the groups in the population.\n- **Here**, the *p*-value is below 0.05 — suggesting that 4/20 days see **significantly less** fatal crashes than other days. The evidence supports a real difference.\n\n\n\n\n\n\n{{< video https://youtu.be/vemZtEM63GY?si=8l3GMwdxxdUI2Rod >}}\n\n\n\n\n\n\n\n\n\n\n#### Simulation-Based Tests\n\nLet’s briefly replicate the comparison using a simulation-based method. This avoids strong distributional assumptions.\n\n::: {#simulation-function .cell execution_count=12}\n``` {.python .cell-code}\ndef simulate_two_groups(data1, data2):\n\n    n, m = len(data1), len(data2)\n    data = np.append(data1, data2)\n    np.random.shuffle(data)\n    group1 = data[:n]\n    group2 = data[n:]\n    return group1.mean() - group2.mean()\n```\n:::\n\n\n::: {#cell-simulation-test .cell execution_count=13}\n``` {.python .cell-code}\n# run 5000 simulations to test null\nnp.random.seed(42)\nsimulated_diffs = [simulate_two_groups(group_420, group_other) for _ in range(5000)]\n\n# observed mean difference\nobserved_diff = group_420.mean() - group_other.mean()\n\n# calculate p-value\ndiffs = np.array(simulated_diffs)\np_sim = np.mean(np.abs(diffs) >= np.abs(observed_diff))\n\n# plot distribution of simulated differences with p-value\nplt.figure(figsize=(12, 6))\nsns.histplot(diffs, kde=True, color='#0081a7')\nplt.axvline(observed_diff, color='#ef233c', linewidth=3, linestyle=\"--\", label='Observed Mean Difference')\nplt.legend(loc='upper right')\nplt.title('Simulated Mean Differences (Permutation Test)')\n\n# annotate p-value on the plot\nplt.text(\n    x=observed_diff+5,\n    y=plt.gca().get_ylim()[1]*0.9,\n    s=f'p-value = {p_sim:.4f}'\n    )\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/simulation-test-output-1.png){#simulation-test}\n:::\n:::\n\n\n**Takeaway:** Simulation confirms the result and emphasizes flexibility: even when assumptions are questionable, we can still test meaningfully. It also reinforces that inference is about what would happen if we repeated the experiment many times.\n\n## Limitations of Comparison\n\nComparing samples of data can be very useful. There is descriptive value in just knowing that differences exist in the data, and this may point to a meaningful difference in the population. However, if you are trying to understand what _caused_ the differences between the two samples, comparison is not enough.\n\n**Questions:** What might be wrong with our comparison?\n\n## Wrapping Up\n\n1. **Workflow recap:**\n   Start with a question → consider population vs. sample → visualize → compare → test → interpret.\n2. **Limits of this approach:**\n   Group comparisons are powerful, but rigid. They don’t account for multiple variables or continuous predictors. Context and sample size also matter.\n3. **Looking ahead:**\n   Next we will move from comparing means to **analysing relationships** between variables. That lets us ask new types of questions. We’ll explore how variables change **together**, detect trends, and lay the foundation for regression.\n\n**Potential extension:** Pick another potentially \"special\" date—e.g., July 4, New Year’s Day—and apply the same steps. Are there elevated crash counts there too? You can also explore other factors, like day of week or holiday status, to dig deeper into what might influence crash rates.\n\n",
    "supporting": [
      "index_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}