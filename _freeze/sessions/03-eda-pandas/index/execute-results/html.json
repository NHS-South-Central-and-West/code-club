{
  "hash": "30928c69af1989a1cf482359553a03a7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Exploring Data Using Pandas\"\nformat:\n  html: default\n  ipynb: default\n---\n\nThis is the first of four sessions looking at how to explore data in Python. This session will focus on introducing the Python library, [pandas](https://pandas.pydata.org/docs/). We will use pandas to import, inspect, summarise, and transform the data, illustrating a typical exploratory data analysis workflow.\n\nWe are using [Australian weather data](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package), taken from [Kaggle](https://kaggle.com). This dataset is used to build machine learning models that predict whether it will rain tomorrow, using data about the weather every day from 2007 to 2017. To download the data, click <a href=\"data/weatherAUS.csv\" download>here</a>.\n\n::: {.callout-note}\n### Please note!\nWe assume that you've created a `uv` project with packages `jupyter`, `pandas`, `numpy` and `seaborn`, and have created a blank notebook in this project and opened it in VS Code. If you're not sure how to do this, please refer back to sessions 1 and 2.\n:::\n\n## Prep work\n\nPlace the `weatherAUS.csv` file you downloaded in a folder called `data` within your project folder.\n\nThere's also one more package we need, called `skimpy`. In your terminal (PowerShell), from within your project folder:\n\n```sh\nuv add skimpy\n```\n\nThen, in your JuPyter notebook in VS Code, create a code cell and start by importing the packages we'll need.\n\n::: {#setup .cell execution_count=1}\n``` {.python .cell-code}\n# Importing packages. This won't work if we didn't add them to our project using uv earlier.\nimport matplotlib.pyplot as plt # \"plt\" (and np, pd, etc below) are called aliases. These are just for convenience and aren't essential...\nimport numpy as np              # ...but it's more convenient to type \"np\" or \"pd\". We can choose whatever alias we want...\nimport pandas as pd             # ...but it's good to stick with common conventions like \"pd\" for pandas.\nimport seaborn as sns           \n\nfrom skimpy import skim\n```\n:::\n\n\n::: {#import-data .cell execution_count=2}\n``` {.python .cell-code}\n# import the dataset using the read_csv function from pandas.\ndf = pd.read_csv('data/weatherAUS.csv') # we're giving our dataframe the name df - we could have chosen whatever we liked.\n```\n:::\n\n\n## Setting the Scene\n\nBefore we start to explore any dataset, we need to establish what we are looking to do with the data. This should inform our decisions wwith any exploration, and any analysis that follows.\n\n**Questions:**\n\n- What are we trying to achieve?\n- How do our goals impact our analysis?\n- What should we take into consideration before we write any code?\n- What sort of questions might we be interested in with this dataset?\n\n### What Our Data Can Tell Us (And What it Can't)\n\nWe also need to consider what the data is and where it came from.\n\n**Questions:**\n\n- How was the data collected?\n- What is it missing?\n- What do the variables in our dataset actually mean, and are they a good approximation of the concepts we are interested in?\n\n## Exploring the Dataset\n\nFirst, we should start with dataset-wide operations.\n\n**Questions:**\n\n- What do we want to know about a dataset when we first encounter it?\n- How do we get a quick overview of the data that can help us in our next steps?\n- We need to get a \"feel\" for the data before we can really make any decisions about how to analyse it. How do we get there with a new dataset?\n\nWe can start by getting a quick glance at the data. The starting point when you have just imported a new dataset is usually the pandas function `.head(n)`, which shows the top $n$ rows of the dataset (by default, if we don't specify a number, it shows the top five rows).\n\n::: {#cell-inspect-data-head .cell execution_count=3}\n``` {.python .cell-code}\n# view the top five rows\ndf.head()\n```\n\n::: {#inspect-data-head .cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-12-01</td>\n      <td>Albury</td>\n      <td>13.4</td>\n      <td>22.9</td>\n      <td>0.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>44.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.7</td>\n      <td>1007.1</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>16.9</td>\n      <td>21.8</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-12-02</td>\n      <td>Albury</td>\n      <td>7.4</td>\n      <td>25.1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>WNW</td>\n      <td>44.0</td>\n      <td>NNW</td>\n      <td>...</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.6</td>\n      <td>1007.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.2</td>\n      <td>24.3</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-12-03</td>\n      <td>Albury</td>\n      <td>12.9</td>\n      <td>25.7</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>WSW</td>\n      <td>46.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.6</td>\n      <td>1008.7</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>21.0</td>\n      <td>23.2</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-12-04</td>\n      <td>Albury</td>\n      <td>9.2</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NE</td>\n      <td>24.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.6</td>\n      <td>1012.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18.1</td>\n      <td>26.5</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-12-05</td>\n      <td>Albury</td>\n      <td>17.5</td>\n      <td>32.3</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>41.0</td>\n      <td>ENE</td>\n      <td>...</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1010.8</td>\n      <td>1006.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>17.8</td>\n      <td>29.7</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\nYou can also look at the bottom rows of the dataset, using `.tail(n)`. This might be useful if you are dealing with time-series data. Below, we specify that we want to look at the bottom ten rows.\n\n::: {#cell-inspect-data-tail .cell execution_count=4}\n``` {.python .cell-code}\n# view the bottom ten rows\ndf.tail(10)\n```\n\n::: {#inspect-data-tail .cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>145450</th>\n      <td>2017-06-16</td>\n      <td>Uluru</td>\n      <td>5.2</td>\n      <td>24.3</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>E</td>\n      <td>24.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>53.0</td>\n      <td>24.0</td>\n      <td>1023.8</td>\n      <td>1020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.3</td>\n      <td>23.3</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145451</th>\n      <td>2017-06-17</td>\n      <td>Uluru</td>\n      <td>6.4</td>\n      <td>23.4</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ESE</td>\n      <td>31.0</td>\n      <td>S</td>\n      <td>...</td>\n      <td>53.0</td>\n      <td>25.0</td>\n      <td>1025.8</td>\n      <td>1023.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.2</td>\n      <td>23.1</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145452</th>\n      <td>2017-06-18</td>\n      <td>Uluru</td>\n      <td>8.0</td>\n      <td>20.7</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ESE</td>\n      <td>41.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>56.0</td>\n      <td>32.0</td>\n      <td>1028.1</td>\n      <td>1024.3</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>11.6</td>\n      <td>20.0</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145453</th>\n      <td>2017-06-19</td>\n      <td>Uluru</td>\n      <td>7.4</td>\n      <td>20.6</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>E</td>\n      <td>35.0</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>63.0</td>\n      <td>33.0</td>\n      <td>1027.2</td>\n      <td>1023.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>20.3</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145454</th>\n      <td>2017-06-20</td>\n      <td>Uluru</td>\n      <td>3.5</td>\n      <td>21.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>E</td>\n      <td>31.0</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>59.0</td>\n      <td>27.0</td>\n      <td>1024.7</td>\n      <td>1021.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.4</td>\n      <td>20.9</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145455</th>\n      <td>2017-06-21</td>\n      <td>Uluru</td>\n      <td>2.8</td>\n      <td>23.4</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>E</td>\n      <td>31.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>51.0</td>\n      <td>24.0</td>\n      <td>1024.6</td>\n      <td>1020.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.1</td>\n      <td>22.4</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145456</th>\n      <td>2017-06-22</td>\n      <td>Uluru</td>\n      <td>3.6</td>\n      <td>25.3</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NNW</td>\n      <td>22.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>56.0</td>\n      <td>21.0</td>\n      <td>1023.5</td>\n      <td>1019.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.9</td>\n      <td>24.5</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145457</th>\n      <td>2017-06-23</td>\n      <td>Uluru</td>\n      <td>5.4</td>\n      <td>26.9</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>37.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>53.0</td>\n      <td>24.0</td>\n      <td>1021.0</td>\n      <td>1016.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.5</td>\n      <td>26.1</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145458</th>\n      <td>2017-06-24</td>\n      <td>Uluru</td>\n      <td>7.8</td>\n      <td>27.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SE</td>\n      <td>28.0</td>\n      <td>SSE</td>\n      <td>...</td>\n      <td>51.0</td>\n      <td>24.0</td>\n      <td>1019.4</td>\n      <td>1016.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>15.1</td>\n      <td>26.0</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>145459</th>\n      <td>2017-06-25</td>\n      <td>Uluru</td>\n      <td>14.9</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>36.0</td>\n      <td>1020.2</td>\n      <td>1017.9</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>15.0</td>\n      <td>20.9</td>\n      <td>No</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\nA quick glimpse at the data is useful, but we may also want to get quick descriptions of several aspects of the data. Such as the length of the dataset (`len()`, which can also be used to get the length of various Python objects), which tells us how many observations we have.\n\n::: {#cell-data-length .cell execution_count=5}\n``` {.python .cell-code}\n# get the object length\nlen(df)\n```\n\n::: {#data-length .cell-output .cell-output-display execution_count=5}\n```\n145460\n```\n:::\n:::\n\n\nAnother option is `pd.DataFrame.shape()`, which shows the length (number of rows) and width (number of columns).\n\n::: {#cell-data-shape .cell execution_count=6}\n``` {.python .cell-code}\n# get the object shape (number of rows, number of columns)\ndf.shape\n```\n\n::: {#data-shape .cell-output .cell-output-display execution_count=6}\n```\n(145460, 23)\n```\n:::\n:::\n\n\nSpeaking of columns, if we want a quick list of the column names, we can get this using `pd.DataFrame.columns()`.\n\n::: {#cell-col-names .cell execution_count=7}\n``` {.python .cell-code}\n# get all column names\ndf.columns\n```\n\n::: {#col-names .cell-output .cell-output-display execution_count=7}\n```\nIndex(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n       'Temp3pm', 'RainToday', 'RainTomorrow'],\n      dtype='object')\n```\n:::\n:::\n\n\nA quick and easy way to get some valuable information about the dataset is `pd.DataFrame.info()`, including the total non-null observations and data type[^Types] of each column.\n\n::: {#data-info .cell execution_count=8}\n``` {.python .cell-code}\n# get dataframe info (column indices, non-null counts, data types)\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 145460 entries, 0 to 145459\nData columns (total 23 columns):\n #   Column         Non-Null Count   Dtype  \n---  ------         --------------   -----  \n 0   Date           145460 non-null  object \n 1   Location       145460 non-null  object \n 2   MinTemp        143975 non-null  float64\n 3   MaxTemp        144199 non-null  float64\n 4   Rainfall       142199 non-null  float64\n 5   Evaporation    82670 non-null   float64\n 6   Sunshine       75625 non-null   float64\n 7   WindGustDir    135134 non-null  object \n 8   WindGustSpeed  135197 non-null  float64\n 9   WindDir9am     134894 non-null  object \n 10  WindDir3pm     141232 non-null  object \n 11  WindSpeed9am   143693 non-null  float64\n 12  WindSpeed3pm   142398 non-null  float64\n 13  Humidity9am    142806 non-null  float64\n 14  Humidity3pm    140953 non-null  float64\n 15  Pressure9am    130395 non-null  float64\n 16  Pressure3pm    130432 non-null  float64\n 17  Cloud9am       89572 non-null   float64\n 18  Cloud3pm       86102 non-null   float64\n 19  Temp9am        143693 non-null  float64\n 20  Temp3pm        141851 non-null  float64\n 21  RainToday      142199 non-null  object \n 22  RainTomorrow   142193 non-null  object \ndtypes: float64(16), object(7)\nmemory usage: 25.5+ MB\n```\n:::\n:::\n\n\nIf we wanted to get a better sense of the null values in each column, we could calculate the percentage of null values by capturing whether each row of each column is null (`pd.DataFrame.isnull()`), summing the total null values in each column (`pd.DataFrame.sum()`), and then dividing by the length of the dataframe (`/len()`).\n\n::: {#cell-null-values-percent .cell execution_count=9}\n``` {.python .cell-code}\n# calculate the percentage of null values in each column\ndf.isnull().sum()/len(df)\n```\n\n::: {#null-values-percent .cell-output .cell-output-display execution_count=9}\n```\nDate             0.000000\nLocation         0.000000\nMinTemp          0.010209\nMaxTemp          0.008669\nRainfall         0.022419\nEvaporation      0.431665\nSunshine         0.480098\nWindGustDir      0.070989\nWindGustSpeed    0.070555\nWindDir9am       0.072639\nWindDir3pm       0.029066\nWindSpeed9am     0.012148\nWindSpeed3pm     0.021050\nHumidity9am      0.018246\nHumidity3pm      0.030984\nPressure9am      0.103568\nPressure3pm      0.103314\nCloud9am         0.384216\nCloud3pm         0.408071\nTemp9am          0.012148\nTemp3pm          0.024811\nRainToday        0.022419\nRainTomorrow     0.022460\ndtype: float64\n```\n:::\n:::\n\n\nIf we want a quick summary of all the numeric columns in the dataset, we can use `pd.DataFrame.describe()`.\n\n::: {#cell-describe-data .cell execution_count=10}\n``` {.python .cell-code}\n# quick summary of numeric variables\ndf.describe()\n```\n\n::: {#describe-data .cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>143975.000000</td>\n      <td>144199.000000</td>\n      <td>142199.000000</td>\n      <td>82670.000000</td>\n      <td>75625.000000</td>\n      <td>135197.000000</td>\n      <td>143693.000000</td>\n      <td>142398.000000</td>\n      <td>142806.000000</td>\n      <td>140953.000000</td>\n      <td>130395.00000</td>\n      <td>130432.000000</td>\n      <td>89572.000000</td>\n      <td>86102.000000</td>\n      <td>143693.000000</td>\n      <td>141851.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>12.194034</td>\n      <td>23.221348</td>\n      <td>2.360918</td>\n      <td>5.468232</td>\n      <td>7.611178</td>\n      <td>40.035230</td>\n      <td>14.043426</td>\n      <td>18.662657</td>\n      <td>68.880831</td>\n      <td>51.539116</td>\n      <td>1017.64994</td>\n      <td>1015.255889</td>\n      <td>4.447461</td>\n      <td>4.509930</td>\n      <td>16.990631</td>\n      <td>21.68339</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.398495</td>\n      <td>7.119049</td>\n      <td>8.478060</td>\n      <td>4.193704</td>\n      <td>3.785483</td>\n      <td>13.607062</td>\n      <td>8.915375</td>\n      <td>8.809800</td>\n      <td>19.029164</td>\n      <td>20.795902</td>\n      <td>7.10653</td>\n      <td>7.037414</td>\n      <td>2.887159</td>\n      <td>2.720357</td>\n      <td>6.488753</td>\n      <td>6.93665</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-8.500000</td>\n      <td>-4.800000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>980.50000</td>\n      <td>977.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-7.200000</td>\n      <td>-5.40000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7.600000</td>\n      <td>17.900000</td>\n      <td>0.000000</td>\n      <td>2.600000</td>\n      <td>4.800000</td>\n      <td>31.000000</td>\n      <td>7.000000</td>\n      <td>13.000000</td>\n      <td>57.000000</td>\n      <td>37.000000</td>\n      <td>1012.90000</td>\n      <td>1010.400000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>12.300000</td>\n      <td>16.60000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>12.000000</td>\n      <td>22.600000</td>\n      <td>0.000000</td>\n      <td>4.800000</td>\n      <td>8.400000</td>\n      <td>39.000000</td>\n      <td>13.000000</td>\n      <td>19.000000</td>\n      <td>70.000000</td>\n      <td>52.000000</td>\n      <td>1017.60000</td>\n      <td>1015.200000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>16.700000</td>\n      <td>21.10000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>16.900000</td>\n      <td>28.200000</td>\n      <td>0.800000</td>\n      <td>7.400000</td>\n      <td>10.600000</td>\n      <td>48.000000</td>\n      <td>19.000000</td>\n      <td>24.000000</td>\n      <td>83.000000</td>\n      <td>66.000000</td>\n      <td>1022.40000</td>\n      <td>1020.000000</td>\n      <td>7.000000</td>\n      <td>7.000000</td>\n      <td>21.600000</td>\n      <td>26.40000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>33.900000</td>\n      <td>48.100000</td>\n      <td>371.000000</td>\n      <td>145.000000</td>\n      <td>14.500000</td>\n      <td>135.000000</td>\n      <td>130.000000</td>\n      <td>87.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>1041.00000</td>\n      <td>1039.600000</td>\n      <td>9.000000</td>\n      <td>9.000000</td>\n      <td>40.200000</td>\n      <td>46.70000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nHowever, I prefer to bring in another package, skimpy, that does all of this very quickly and cleanly. We can get a detailed description of the entire dataset using `skim()`.\n\n::: {#cell-summarise-data .cell execution_count=11}\n``` {.python .cell-code}\n# a more informative summary function from the skimpy package\nskim(df)\n```\n\n::: {#summarise-data .cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n│ <span style=\"font-style: italic\">         Data Summary         </span> <span style=\"font-style: italic\">      Data Types       </span>                                                          │\n│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃                                                          │\n│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n│ │ Number of rows    │ 145460 │ │ float64     │ 16    │                                                          │\n│ │ Number of columns │ 23     │ │ string      │ 7     │                                                          │\n│ └───────────────────┴────────┘ └─────────────┴───────┘                                                          │\n│ <span style=\"font-style: italic\">                                                    number                                                    </span>  │\n│ ┏━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━━━┓  │\n│ ┃<span style=\"font-weight: bold\"> column         </span>┃<span style=\"font-weight: bold\"> NA     </span>┃<span style=\"font-weight: bold\"> NA %                </span>┃<span style=\"font-weight: bold\"> mean  </span>┃<span style=\"font-weight: bold\"> sd    </span>┃<span style=\"font-weight: bold\"> p0    </span>┃<span style=\"font-weight: bold\"> p25  </span>┃<span style=\"font-weight: bold\"> p50  </span>┃<span style=\"font-weight: bold\"> p75  </span>┃<span style=\"font-weight: bold\"> p100 </span>┃<span style=\"font-weight: bold\"> hist   </span>┃  │\n│ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━━━┩  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">MinTemp       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  1485</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.0208992162793895</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">12.19</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">6.398</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -8.5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 7.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  12</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">16.9</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">33.9</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▃▇▇▃ </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">MaxTemp       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  1261</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.8669049910628351</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">23.22</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">7.119</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -4.8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">17.9</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">22.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">28.2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">48.1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▁▇▇▃ </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Rainfall      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  3261</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  2.241853430496356</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">2.361</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">8.478</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 371</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  ▇   </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Evaporation   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 62790</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   43.1665062560154</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">5.468</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">4.194</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 2.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4.8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 7.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 145</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  ▇   </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Sunshine      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 69835</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  48.00976213391998</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">7.611</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">3.785</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4.8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 8.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">10.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">14.5</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▃▃▅▆▇▃</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WindGustSpeed </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 10263</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  7.055547916953114</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">40.04</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">13.61</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  31</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  39</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  48</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 135</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▂▇▂  </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WindSpeed9am  </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  1767</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  1.214766946239516</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">14.04</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">8.915</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   7</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  13</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  19</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 130</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  ▇▂  </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WindSpeed3pm  </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  3062</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  2.105046060772721</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">18.66</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 8.81</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  13</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  19</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  24</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  87</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▅▇▂  </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Humidity9am   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  2654</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.8245565791282827</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">68.88</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">19.03</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  57</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  70</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  83</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 100</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▁▂▇▇▆</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Humidity3pm   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  4507</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   3.09844630826344</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">51.54</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 20.8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  37</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  52</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  66</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 100</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▁▅▆▇▅▂</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Pressure9am   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 15065</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    10.356799120033</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1018</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">7.107</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">980.5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1013</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1018</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1022</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1041</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  ▂▇▅ </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Pressure3pm   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 15028</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 10.331362573903478</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1015</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">7.037</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">977.1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1010</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1015</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1020</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1040</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  ▂▇▅ </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Cloud9am      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 55888</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  38.42155919153032</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">4.447</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">2.887</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   7</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   9</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇▂▃▂▇▅</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Cloud3pm      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 59358</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  40.80709473394748</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4.51</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 2.72</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   7</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   9</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▆▂▃▂▇▃</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Temp9am       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  1767</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  1.214766946239516</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">16.99</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">6.489</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -7.2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">12.3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">16.7</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">21.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">40.2</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▂▇▇▃ </span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Temp3pm       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  3609</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 2.4810944589577892</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">21.68</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">6.937</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -5.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">16.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">21.1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">26.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">46.7</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▁▇▇▃ </span> │  │\n│ └────────────────┴────────┴─────────────────────┴───────┴───────┴───────┴──────┴──────┴──────┴──────┴────────┘  │\n│ <span style=\"font-style: italic\">                                                    string                                                    </span>  │\n│ ┏━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓  │\n│ ┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">       </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\"> chars per </span>┃<span style=\"font-weight: bold\"> words    </span>┃<span style=\"font-weight: bold\"> total     </span>┃  │\n│ ┃<span style=\"font-weight: bold\"> column   </span>┃<span style=\"font-weight: bold\"> NA    </span>┃<span style=\"font-weight: bold\"> NA %     </span>┃<span style=\"font-weight: bold\"> shortest </span>┃<span style=\"font-weight: bold\"> longest  </span>┃<span style=\"font-weight: bold\"> min      </span>┃<span style=\"font-weight: bold\"> max      </span>┃<span style=\"font-weight: bold\"> row       </span>┃<span style=\"font-weight: bold\"> per row  </span>┃<span style=\"font-weight: bold\"> words     </span>┃  │\n│ ┡━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Date    </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       0</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">2008-12-</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">2008-12-</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">2007-11-</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">2017-06-</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       10</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   145460</span> │  │\n│ │          │       │          │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">01      </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">01      </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">01      </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">25      </span> │           │          │           │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Location</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       0</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Sale    </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Melbourn</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Adelaide</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Woomera </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     8.71</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   145460</span> │  │\n│ │          │       │          │          │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">eAirport</span> │          │          │           │          │           │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WindGust</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">10326</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">7.098858</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">W       </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WNW     </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">E       </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WSW     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     2.19</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.93</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   135134</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Dir     </span> │       │ <span style=\"color: #008080; text-decoration-color: #008080\">79279527</span> │          │          │          │          │           │          │           │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WindDir9</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">10566</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">7.263852</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">W       </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">NNW     </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">E       </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WSW     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     2.18</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.93</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   134894</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">am      </span> │       │ <span style=\"color: #008080; text-decoration-color: #008080\">60552729</span> │          │          │          │          │           │          │           │  │\n│ │          │       │ <span style=\"color: #008080; text-decoration-color: #008080\">       2</span> │          │          │          │          │           │          │           │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WindDir3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4228</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">2.906641</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">E       </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WNW     </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">E       </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">WSW     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     2.21</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.97</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   141232</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">pm      </span> │       │ <span style=\"color: #008080; text-decoration-color: #008080\">00096246</span> │          │          │          │          │           │          │           │  │\n│ │          │       │ <span style=\"color: #008080; text-decoration-color: #008080\">       4</span> │          │          │          │          │           │          │           │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">RainToda</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 3261</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">2.241853</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">No      </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Yes     </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">No      </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Yes     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     2.22</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.98</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   142199</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">y       </span> │       │ <span style=\"color: #008080; text-decoration-color: #008080\">43049635</span> │          │          │          │          │           │          │           │  │\n│ │          │       │ <span style=\"color: #008080; text-decoration-color: #008080\">       6</span> │          │          │          │          │           │          │           │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">RainTomo</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 3267</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">2.245978</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">No      </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Yes     </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">No      </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Yes     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     2.22</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.98</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   142193</span> │  │\n│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">rrow    </span> │       │ <span style=\"color: #008080; text-decoration-color: #008080\">27581465</span> │          │          │          │          │           │          │           │  │\n│ │          │       │ <span style=\"color: #008080; text-decoration-color: #008080\">       7</span> │          │          │          │          │           │          │           │  │\n│ └──────────┴───────┴──────────┴──────────┴──────────┴──────────┴──────────┴───────────┴──────────┴───────────┘  │\n╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n</pre>\n```\n:::\n:::\n\n\n[^Types]:\n\nFor more information about pandas data types, check out the pandas documentation on [dtypes](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics-dtypes).\n\n## Exploring Variables (Columns) & Observations (Rows)\n\nIf we are going to narrow our focus to specific variables or groups of observations, we need to know how to select columns, filter values, and group the data. There are lots of different ways we can slice up the data. We won't cover all of them here[^Docs], but we will try to cover a range that helps illustrate how pandas works and will help you build the intuition for working with data in pandas.\n\nWe can select columns in a variety of ways, but the \"correct\" way to select columns in most circumstances is using selection brackets (the square brackets `[]`), also known as the indexing operator.\n\n::: {#cell-select-col .cell execution_count=12}\n``` {.python .cell-code}\n# selecting a single column by name\ndf['Date']\n\n# alternative ways to select columns\n# df.loc[:, 'Date']\n# df.Date\n```\n\n::: {#select-col .cell-output .cell-output-display execution_count=12}\n```\n0         2008-12-01\n1         2008-12-02\n2         2008-12-03\n3         2008-12-04\n4         2008-12-05\n             ...    \n145455    2017-06-21\n145456    2017-06-22\n145457    2017-06-23\n145458    2017-06-24\n145459    2017-06-25\nName: Date, Length: 145460, dtype: object\n```\n:::\n:::\n\n\nIf we want to select multiple columns, we can use double squared brackets (`[[ ]]`). This is the same process as before, but the inner brackets define a list, and the outer are the selection brackets.\n\n::: {#cell-select-multiple-cols .cell execution_count=13}\n``` {.python .cell-code}\n# selecting multiple columns (and all rows) by name\ndf[['Date', 'Location', 'Rainfall']]\n# df.loc[:, ['Date', 'Location', 'Rainfall']]\n```\n\n::: {#select-multiple-cols .cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>Rainfall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-12-01</td>\n      <td>Albury</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-12-02</td>\n      <td>Albury</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-12-03</td>\n      <td>Albury</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-12-04</td>\n      <td>Albury</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-12-05</td>\n      <td>Albury</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145455</th>\n      <td>2017-06-21</td>\n      <td>Uluru</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145456</th>\n      <td>2017-06-22</td>\n      <td>Uluru</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145457</th>\n      <td>2017-06-23</td>\n      <td>Uluru</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145458</th>\n      <td>2017-06-24</td>\n      <td>Uluru</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145459</th>\n      <td>2017-06-25</td>\n      <td>Uluru</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>145460 rows × 3 columns</p>\n</div>\n```\n:::\n:::\n\n\nWhile selection brackets are a quick and easy solution if we want to grab a subset of variables in the dataset, it is realy only intended to be used for simple operations using only column selection.\n\nFor row selection, we should use `pd.DataFrame.iloc[]`. The `iloc` function is used for \"integer position\" selection, which means you can select rows or columns using their integer position. For rows 10-15, you can select them using the following:\n\n::: {#cell-subset-rows .cell execution_count=14}\n``` {.python .cell-code}\n# slicing by rows\ndf.iloc[10:16]\n```\n\n::: {#subset-rows .cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>2008-12-11</td>\n      <td>Albury</td>\n      <td>13.4</td>\n      <td>30.4</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>30.0</td>\n      <td>SSE</td>\n      <td>...</td>\n      <td>48.0</td>\n      <td>22.0</td>\n      <td>1011.8</td>\n      <td>1008.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.4</td>\n      <td>28.8</td>\n      <td>No</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2008-12-12</td>\n      <td>Albury</td>\n      <td>15.9</td>\n      <td>21.7</td>\n      <td>2.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NNE</td>\n      <td>31.0</td>\n      <td>NE</td>\n      <td>...</td>\n      <td>89.0</td>\n      <td>91.0</td>\n      <td>1010.5</td>\n      <td>1004.2</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>15.9</td>\n      <td>17.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2008-12-13</td>\n      <td>Albury</td>\n      <td>15.9</td>\n      <td>18.6</td>\n      <td>15.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>61.0</td>\n      <td>NNW</td>\n      <td>...</td>\n      <td>76.0</td>\n      <td>93.0</td>\n      <td>994.3</td>\n      <td>993.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>17.4</td>\n      <td>15.8</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2008-12-14</td>\n      <td>Albury</td>\n      <td>12.6</td>\n      <td>21.0</td>\n      <td>3.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SW</td>\n      <td>44.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>65.0</td>\n      <td>43.0</td>\n      <td>1001.2</td>\n      <td>1001.8</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>15.8</td>\n      <td>19.8</td>\n      <td>Yes</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2008-12-15</td>\n      <td>Albury</td>\n      <td>8.4</td>\n      <td>24.6</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>...</td>\n      <td>57.0</td>\n      <td>32.0</td>\n      <td>1009.7</td>\n      <td>1008.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.9</td>\n      <td>23.5</td>\n      <td>No</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2008-12-16</td>\n      <td>Albury</td>\n      <td>9.8</td>\n      <td>27.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>WNW</td>\n      <td>50.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>50.0</td>\n      <td>28.0</td>\n      <td>1013.4</td>\n      <td>1010.3</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>17.3</td>\n      <td>26.2</td>\n      <td>NaN</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\nWe can do similar using a column's integer position, but we have to select all rows (`:`) first:\n\n::: {#cell-col-iloc .cell execution_count=15}\n``` {.python .cell-code}\n# using iloc with columns\ndf.iloc[:, 20]\n```\n\n::: {#col-iloc .cell-output .cell-output-display execution_count=15}\n```\n0         21.8\n1         24.3\n2         23.2\n3         26.5\n4         29.7\n          ... \n145455    22.4\n145456    24.5\n145457    26.1\n145458    26.0\n145459    20.9\nName: Temp3pm, Length: 145460, dtype: float64\n```\n:::\n:::\n\n\nFinally, we can put both together to take a subset of both rows and columns:\n\n::: {#cell-col-rows-iloc .cell execution_count=16}\n``` {.python .cell-code}\n# using iloc with rows and columns\ndf.iloc[10:16, 20]\n```\n\n::: {#col-rows-iloc .cell-output .cell-output-display execution_count=16}\n```\n10    28.8\n11    17.0\n12    15.8\n13    19.8\n14    23.5\n15    26.2\nName: Temp3pm, dtype: float64\n```\n:::\n:::\n\n\nHowever, selecting by integer position is relatively limited. It is more likely we would want to subset the data based on the values of certain columns. We can filter rows by condition using `pd.DataFrame.loc[]`. The `loc` function slices by label, instead of integer position.\n\nFor example, we might want to look at a subset of the data based on location.\n\n::: {#cell-filter-location .cell execution_count=17}\n``` {.python .cell-code}\n# select all observations in Perth\ndf.loc[df['Location'] == 'Perth']\n```\n\n::: {#filter-location .cell-output .cell-output-display execution_count=17}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>120638</th>\n      <td>2008-07-01</td>\n      <td>Perth</td>\n      <td>2.7</td>\n      <td>18.8</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>9.1</td>\n      <td>ENE</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>97.0</td>\n      <td>53.0</td>\n      <td>1027.6</td>\n      <td>1024.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.5</td>\n      <td>18.1</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>120639</th>\n      <td>2008-07-02</td>\n      <td>Perth</td>\n      <td>6.4</td>\n      <td>20.7</td>\n      <td>0.0</td>\n      <td>1.8</td>\n      <td>7.0</td>\n      <td>NE</td>\n      <td>22.0</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>80.0</td>\n      <td>39.0</td>\n      <td>1024.1</td>\n      <td>1019.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>11.1</td>\n      <td>19.7</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>120640</th>\n      <td>2008-07-03</td>\n      <td>Perth</td>\n      <td>6.5</td>\n      <td>19.9</td>\n      <td>0.4</td>\n      <td>2.2</td>\n      <td>7.3</td>\n      <td>NE</td>\n      <td>31.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>84.0</td>\n      <td>71.0</td>\n      <td>1016.8</td>\n      <td>1015.6</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>12.1</td>\n      <td>17.7</td>\n      <td>No</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>120641</th>\n      <td>2008-07-04</td>\n      <td>Perth</td>\n      <td>9.5</td>\n      <td>19.2</td>\n      <td>1.8</td>\n      <td>1.2</td>\n      <td>4.7</td>\n      <td>W</td>\n      <td>26.0</td>\n      <td>NNE</td>\n      <td>...</td>\n      <td>93.0</td>\n      <td>73.0</td>\n      <td>1019.3</td>\n      <td>1018.4</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>13.2</td>\n      <td>17.7</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>120642</th>\n      <td>2008-07-05</td>\n      <td>Perth</td>\n      <td>9.5</td>\n      <td>16.4</td>\n      <td>1.8</td>\n      <td>1.4</td>\n      <td>4.9</td>\n      <td>WSW</td>\n      <td>44.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>69.0</td>\n      <td>57.0</td>\n      <td>1020.4</td>\n      <td>1022.1</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>15.9</td>\n      <td>16.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123826</th>\n      <td>2017-06-21</td>\n      <td>Perth</td>\n      <td>10.3</td>\n      <td>19.9</td>\n      <td>0.2</td>\n      <td>1.8</td>\n      <td>7.5</td>\n      <td>NW</td>\n      <td>37.0</td>\n      <td>NNE</td>\n      <td>...</td>\n      <td>89.0</td>\n      <td>60.0</td>\n      <td>1017.1</td>\n      <td>1013.8</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>13.0</td>\n      <td>18.5</td>\n      <td>No</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>123827</th>\n      <td>2017-06-22</td>\n      <td>Perth</td>\n      <td>13.0</td>\n      <td>16.8</td>\n      <td>61.2</td>\n      <td>3.6</td>\n      <td>0.0</td>\n      <td>SSW</td>\n      <td>46.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>90.0</td>\n      <td>75.0</td>\n      <td>1005.6</td>\n      <td>1008.9</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>16.4</td>\n      <td>15.6</td>\n      <td>Yes</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>123828</th>\n      <td>2017-06-23</td>\n      <td>Perth</td>\n      <td>13.3</td>\n      <td>18.9</td>\n      <td>0.4</td>\n      <td>1.8</td>\n      <td>6.5</td>\n      <td>SE</td>\n      <td>37.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>85.0</td>\n      <td>65.0</td>\n      <td>1019.2</td>\n      <td>1019.4</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>15.1</td>\n      <td>18.0</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>123829</th>\n      <td>2017-06-24</td>\n      <td>Perth</td>\n      <td>11.5</td>\n      <td>18.2</td>\n      <td>0.0</td>\n      <td>3.8</td>\n      <td>9.3</td>\n      <td>SE</td>\n      <td>30.0</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>47.0</td>\n      <td>1025.9</td>\n      <td>1023.4</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>14.0</td>\n      <td>17.6</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>123830</th>\n      <td>2017-06-25</td>\n      <td>Perth</td>\n      <td>6.3</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>1.6</td>\n      <td>7.9</td>\n      <td>E</td>\n      <td>26.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>75.0</td>\n      <td>49.0</td>\n      <td>1028.6</td>\n      <td>1026.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>11.5</td>\n      <td>15.6</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>3193 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\nWe can also filter by multiple values, such as location and rainfall.\n\n::: {#cell-filter-multiple-vals .cell execution_count=18}\n``` {.python .cell-code}\ndf.loc[(df['Rainfall'] == 0) & (df['Location'] == 'Perth')]\n```\n\n::: {#filter-multiple-vals .cell-output .cell-output-display execution_count=18}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>120638</th>\n      <td>2008-07-01</td>\n      <td>Perth</td>\n      <td>2.7</td>\n      <td>18.8</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>9.1</td>\n      <td>ENE</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>97.0</td>\n      <td>53.0</td>\n      <td>1027.6</td>\n      <td>1024.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.5</td>\n      <td>18.1</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>120639</th>\n      <td>2008-07-02</td>\n      <td>Perth</td>\n      <td>6.4</td>\n      <td>20.7</td>\n      <td>0.0</td>\n      <td>1.8</td>\n      <td>7.0</td>\n      <td>NE</td>\n      <td>22.0</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>80.0</td>\n      <td>39.0</td>\n      <td>1024.1</td>\n      <td>1019.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>11.1</td>\n      <td>19.7</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>120644</th>\n      <td>2008-07-07</td>\n      <td>Perth</td>\n      <td>0.7</td>\n      <td>18.3</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>9.3</td>\n      <td>N</td>\n      <td>37.0</td>\n      <td>NE</td>\n      <td>...</td>\n      <td>72.0</td>\n      <td>36.0</td>\n      <td>1028.9</td>\n      <td>1024.2</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>8.7</td>\n      <td>17.9</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>120645</th>\n      <td>2008-07-08</td>\n      <td>Perth</td>\n      <td>3.2</td>\n      <td>20.4</td>\n      <td>0.0</td>\n      <td>1.4</td>\n      <td>6.9</td>\n      <td>NNW</td>\n      <td>24.0</td>\n      <td>NE</td>\n      <td>...</td>\n      <td>58.0</td>\n      <td>42.0</td>\n      <td>1023.9</td>\n      <td>1021.1</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>10.2</td>\n      <td>19.3</td>\n      <td>No</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>120651</th>\n      <td>2008-07-14</td>\n      <td>Perth</td>\n      <td>7.9</td>\n      <td>19.7</td>\n      <td>0.0</td>\n      <td>0.2</td>\n      <td>6.5</td>\n      <td>NE</td>\n      <td>31.0</td>\n      <td>NE</td>\n      <td>...</td>\n      <td>86.0</td>\n      <td>41.0</td>\n      <td>1026.0</td>\n      <td>1021.9</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>11.7</td>\n      <td>18.7</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123823</th>\n      <td>2017-06-18</td>\n      <td>Perth</td>\n      <td>7.5</td>\n      <td>23.4</td>\n      <td>0.0</td>\n      <td>1.8</td>\n      <td>9.2</td>\n      <td>NNE</td>\n      <td>28.0</td>\n      <td>ENE</td>\n      <td>...</td>\n      <td>67.0</td>\n      <td>41.0</td>\n      <td>1026.9</td>\n      <td>1022.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.2</td>\n      <td>22.2</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>123824</th>\n      <td>2017-06-19</td>\n      <td>Perth</td>\n      <td>5.5</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>9.1</td>\n      <td>SW</td>\n      <td>19.0</td>\n      <td>ENE</td>\n      <td>...</td>\n      <td>84.0</td>\n      <td>55.0</td>\n      <td>1023.0</td>\n      <td>1020.3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>11.5</td>\n      <td>22.0</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>123825</th>\n      <td>2017-06-20</td>\n      <td>Perth</td>\n      <td>7.8</td>\n      <td>22.5</td>\n      <td>0.0</td>\n      <td>2.8</td>\n      <td>9.1</td>\n      <td>NW</td>\n      <td>26.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>98.0</td>\n      <td>59.0</td>\n      <td>1019.3</td>\n      <td>1015.9</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>13.5</td>\n      <td>21.6</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>123829</th>\n      <td>2017-06-24</td>\n      <td>Perth</td>\n      <td>11.5</td>\n      <td>18.2</td>\n      <td>0.0</td>\n      <td>3.8</td>\n      <td>9.3</td>\n      <td>SE</td>\n      <td>30.0</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>47.0</td>\n      <td>1025.9</td>\n      <td>1023.4</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>14.0</td>\n      <td>17.6</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>123830</th>\n      <td>2017-06-25</td>\n      <td>Perth</td>\n      <td>6.3</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>1.6</td>\n      <td>7.9</td>\n      <td>E</td>\n      <td>26.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>75.0</td>\n      <td>49.0</td>\n      <td>1028.6</td>\n      <td>1026.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>11.5</td>\n      <td>15.6</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>2293 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\nFor any complex process for subsetting the data, including multiple conditions, `pd.DataFrame.loc[]` is the best bet.\n\n[^Docs]:\n\nFor more information, I'd recommend the [pandas documentation](https://pandas.pydata.org/docs/), and this pandas tutorial on [subsetting data](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html).\n\n### Summarising Data\n\nNow that we know how to select the variables or observations we are interested in, we can start doing some descriptive analysis. The operations we use will depend on the questions we are trying to answer, and the possibilities will be almost endless.\n\n**Questions:**\n\n- What \"functions\" might we need to carry out on our data when we are exploring it?\n\nWe know that the weather data includes observations from all over the country, but we might want to check exactly how many different locations there are. We can use `pd.DataFrame.nunique()` to do this.\n\n::: {#cell-count-unique .cell execution_count=19}\n``` {.python .cell-code}\n# count unique values\ndf['Location'].nunique()\n```\n\n::: {#count-unique .cell-output .cell-output-display execution_count=19}\n```\n49\n```\n:::\n:::\n\n\nWe may also be interested in the locations themselves, which may tell us more about the spatial distribution of our data. In this case, we can use `pd.DataFrame.unique()`.\n\n::: {#cell-unique-vals .cell execution_count=20}\n``` {.python .cell-code}\n# get unique values\ndf['Location'].unique()\n```\n\n::: {#unique-vals .cell-output .cell-output-display execution_count=20}\n```\narray(['Albury', 'BadgerysCreek', 'Cobar', 'CoffsHarbour', 'Moree',\n       'Newcastle', 'NorahHead', 'NorfolkIsland', 'Penrith', 'Richmond',\n       'Sydney', 'SydneyAirport', 'WaggaWagga', 'Williamtown',\n       'Wollongong', 'Canberra', 'Tuggeranong', 'MountGinini', 'Ballarat',\n       'Bendigo', 'Sale', 'MelbourneAirport', 'Melbourne', 'Mildura',\n       'Nhil', 'Portland', 'Watsonia', 'Dartmoor', 'Brisbane', 'Cairns',\n       'GoldCoast', 'Townsville', 'Adelaide', 'MountGambier', 'Nuriootpa',\n       'Woomera', 'Albany', 'Witchcliffe', 'PearceRAAF', 'PerthAirport',\n       'Perth', 'SalmonGums', 'Walpole', 'Hobart', 'Launceston',\n       'AliceSprings', 'Darwin', 'Katherine', 'Uluru'], dtype=object)\n```\n:::\n:::\n\n\nAnother common operation we might look to do is calculating the mean value (`pd.DataFrame.mean()`) of a certain variable. What is the average value of sunshine across the entire dataset?\n\n::: {#cell-simple-mean .cell execution_count=21}\n``` {.python .cell-code}\n# calculate variable mean\ndf['Sunshine'].mean()\n```\n\n::: {#simple-mean .cell-output .cell-output-display execution_count=21}\n```\nnp.float64(7.6111775206611565)\n```\n:::\n:::\n\n\nThis gives us the mean to many decimal places, and we probably don't need to know the average sunshine hours to this level of precision. We can use the `pd.DataFrame.round()` function to round to two decimal places.\n\n::: {#cell-rounded-mean .cell execution_count=22}\n``` {.python .cell-code}\n# round mean value\ndf['Sunshine'].mean().round(2)\n```\n\n::: {#rounded-mean .cell-output .cell-output-display execution_count=22}\n```\nnp.float64(7.61)\n```\n:::\n:::\n\n\nMany operations will return the value with information about the object's type included. The above values are wrapped in `np.float64()` because `pd.DataFrame.mean()` uses numpy to calculate the mean value. However, if you want to strip this information out so you only see the value itself, you can use `print()`.\n\n::: {#print-values .cell execution_count=23}\n``` {.python .cell-code}\n# print mean value\nprint(df['Sunshine'].mean().round(2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n7.61\n```\n:::\n:::\n\n\nWhile we are often interested in the mean value when we talk about averages, we might want to know the median instead (`pd.DataFrame.median()`).\n\n::: {#median .cell execution_count=24}\n``` {.python .cell-code}\n# calculate other summary statistics\nprint(df['Sunshine'].median())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n8.4\n```\n:::\n:::\n\n\nAnother common calculation is summing values (`pd.DataFrame.sum()`). We can use `sum()` to see the total hours of sunshine in our dataset, and we can use `int()` to convert this value to an integer (which also means we don't need to use `print()`[^Print]).\n\n::: {#cell-sum .cell execution_count=25}\n``` {.python .cell-code}\n# calculate sum value and return an integer\nint(df['Sunshine'].sum())\n```\n\n::: {#sum .cell-output .cell-output-display execution_count=25}\n```\n575595\n```\n:::\n:::\n\n\nWe can also apply these summary operations on multiple variables, using the same selection logic as before (using double squared brackets).\n\n::: {#summarise-multiple-cols .cell execution_count=26}\n``` {.python .cell-code}\nprint(df[['Sunshine', 'Rainfall']].mean())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSunshine    7.611178\nRainfall    2.360918\ndtype: float64\n```\n:::\n:::\n\n\nAnd we can apply multiple functions, using `pd.DataFrame.agg()`.\n\n::: {#cell-agg .cell execution_count=27}\n``` {.python .cell-code}\ndf['Sunshine'].agg(['mean', 'median', 'sum']).round(1)\n```\n\n::: {#agg .cell-output .cell-output-display execution_count=27}\n```\nmean           7.6\nmedian         8.4\nsum       575595.3\nName: Sunshine, dtype: float64\n```\n:::\n:::\n\n\nThe next step when exploring specific variables will often be group-level summaries. The average amount of sunshine across the whole dataset has limited utility, but the average hours of sunshine in each location allows us to compare between locations and start to understand how different variables are related to each other. If we want to do a group-level operation, we have to use `pd.DataFrame.groupby()`.\n\n::: {#cell-group-means .cell execution_count=28}\n``` {.python .cell-code}\n# calculate group means\ndf.groupby(by='Location')['Sunshine'].mean().round(1)\n```\n\n::: {#group-means .cell-output .cell-output-display execution_count=28}\n```\nLocation\nAdelaide            7.7\nAlbany              6.7\nAlbury              NaN\nAliceSprings        9.6\nBadgerysCreek       NaN\nBallarat            NaN\nBendigo             NaN\nBrisbane            8.1\nCairns              7.6\nCanberra            7.4\nCobar               8.7\nCoffsHarbour        7.4\nDartmoor            6.5\nDarwin              8.5\nGoldCoast           NaN\nHobart              6.6\nKatherine           NaN\nLaunceston          NaN\nMelbourne           6.4\nMelbourneAirport    6.4\nMildura             8.5\nMoree               8.9\nMountGambier        6.5\nMountGinini         NaN\nNewcastle           NaN\nNhil                NaN\nNorahHead           NaN\nNorfolkIsland       7.0\nNuriootpa           7.7\nPearceRAAF          8.8\nPenrith             NaN\nPerth               8.8\nPerthAirport        8.8\nPortland            6.5\nRichmond            NaN\nSale                6.7\nSalmonGums          NaN\nSydney              7.2\nSydneyAirport       7.2\nTownsville          8.5\nTuggeranong         NaN\nUluru               NaN\nWaggaWagga          8.2\nWalpole             NaN\nWatsonia            6.4\nWilliamtown         7.2\nWitchcliffe         NaN\nWollongong          NaN\nWoomera             9.0\nName: Sunshine, dtype: float64\n```\n:::\n:::\n\n\nThe `groupby(by='Location')` function tells us the grouping variable (location), then we select the variable we want to summarise by location (sunshine), and then we specify the operation (mean).\n\nThere are multiple locations that return `NaN` (**N**ot **a** **N**umber). This indicates that numpy was unable to calculate a mean value for those locations. This is likely to be because all sunshine values for those locations are null.\n\nWe can check this using `pd.DataFrame.count()`, which counts the total non-null values (whereas `pd.DataFrame.size()` counts the total values).\n\n::: {#cell-count-group-non-nulls .cell execution_count=29}\n``` {.python .cell-code}\n# group by location and count non-null sunshine values\ndf.groupby('Location')['Sunshine'].count()\n```\n\n::: {#count-group-non-nulls .cell-output .cell-output-display execution_count=29}\n```\nLocation\nAdelaide            1769\nAlbany              2520\nAlbury                 0\nAliceSprings        2520\nBadgerysCreek          0\nBallarat               0\nBendigo                0\nBrisbane            3144\nCairns              2564\nCanberra            1521\nCobar                550\nCoffsHarbour        1494\nDartmoor            2566\nDarwin              3189\nGoldCoast              0\nHobart              3179\nKatherine              0\nLaunceston             0\nMelbourne           3192\nMelbourneAirport    3008\nMildura             2876\nMoree               2055\nMountGambier        2597\nMountGinini            0\nNewcastle              0\nNhil                   0\nNorahHead              0\nNorfolkIsland       2570\nNuriootpa           2848\nPearceRAAF          3004\nPenrith                0\nPerth               3188\nPerthAirport        3004\nPortland            2566\nRichmond               0\nSale                1818\nSalmonGums             0\nSydney              3328\nSydneyAirport       2993\nTownsville          2617\nTuggeranong            0\nUluru                  0\nWaggaWagga          2575\nWalpole                0\nWatsonia            3008\nWilliamtown         1355\nWitchcliffe            0\nWollongong             0\nWoomera             2007\nName: Sunshine, dtype: int64\n```\n:::\n:::\n\n\nThe results show that all the locations that return `NaN` in our group mean calculation have zero non-null values.\n\n[^Print]:\n\nSome functions should be wrapped in `print()` in order to return a value that is easy to read, but others won't. There will be an internal logic for which is which, but it's not of huge importance to us. You are better off just testing functions out and wrapping them in `print()` if necessary.\n\n## Transforming Data\n\nDatasets are rarely perfectly clean and [tidy](https://vita.had.co.nz/papers/tidy-data.pdf). We often need to transform the data before we can get the most out of it.\n\n**Questions:**\n\n- What sort of transformations would help us get the most out of the analysis of the Australian weather data?\n\nThe first step with any analysis is often converting columns to the correct types. With a longitudinal (time-series) dataset,the date column is a good place to start. We can use `pd.DataFrame.dtypes` to check the data type, either of a single column (using the selector brackets) or all columns in the dataset.\n\n::: {#data-types .cell execution_count=30}\n``` {.python .cell-code}\nprint(df.dtypes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDate              object\nLocation          object\nMinTemp          float64\nMaxTemp          float64\nRainfall         float64\nEvaporation      float64\nSunshine         float64\nWindGustDir       object\nWindGustSpeed    float64\nWindDir9am        object\nWindDir3pm        object\nWindSpeed9am     float64\nWindSpeed3pm     float64\nHumidity9am      float64\nHumidity3pm      float64\nPressure9am      float64\nPressure3pm      float64\nCloud9am         float64\nCloud3pm         float64\nTemp9am          float64\nTemp3pm          float64\nRainToday         object\nRainTomorrow      object\ndtype: object\n```\n:::\n:::\n\n\nAll columns are either stored as `object` or `float64`. The `object` data type is for generic non-numeric data, but from the columns that are stored as objects, we can tell this is mostly categorical variables where the categories are represented as text. The float64 data type refers to data that is numeric and includes decimals (float64 = 64-bit floating point number).\n\nThe date column is stored as an object, but pandas can store dates as `datetime64`. We can convert dates using `pd.to_datetime()`. When transforming data, if we want to keep those transformations, we have to store those changes, using `=`. In this case, we want to convert the date column but we don't want to create an entirely new dataframe to handle this change, so we can overwrite the current date column by using the selection brackets to identify the column we want to apply this change to.\n\n::: {#convert-to-datetime .cell execution_count=31}\n``` {.python .cell-code}\n# convert date column to datetime\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n:::\n\n\nThe remaining `object` columns can be converted to categorical, which makes them easier to work with in subsequent analyses. We can use `pd.DataFrame.astype()` to convert column data types.\n\n::: {#convert-cols .cell execution_count=32}\n``` {.python .cell-code}\n# create a list of all object columns\nobject_cols = ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n\n# convert object columns to category\ndf[object_cols] = df[object_cols].astype('category')\n```\n:::\n\n\nA more efficient, though synactically more complex, way of doing this is using lamda functions. We won't cover lambda functons in this session (they will be discussed in detail in a future session), but below is how we can use them to convert objects to categories.\n\n::: {#convert-to-cat .cell execution_count=33}\n``` {.python .cell-code}\n# convert object columns to category data type\ndf = df.apply(lambda x: x.astype('category') if x.dtype == 'object' else x)\n```\n:::\n\n\nAnother choice we might make is to remove missing values, using `pd.DataFrame.dropna()` to filter the null values and keep only the non-null values. We can use this to drop all null values across the entire dataset, or we can apply it to a subset of columns, using the `subset` argument.\n\n::: {#cell-filter-not-null .cell execution_count=34}\n``` {.python .cell-code}\n# filter observations where sunshine is NA\ndf.dropna(subset='Sunshine')\n```\n\n::: {#filter-not-null .cell-output .cell-output-display execution_count=34}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6049</th>\n      <td>2009-01-01</td>\n      <td>Cobar</td>\n      <td>17.9</td>\n      <td>35.2</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>12.3</td>\n      <td>SSW</td>\n      <td>48.0</td>\n      <td>ENE</td>\n      <td>...</td>\n      <td>20.0</td>\n      <td>13.0</td>\n      <td>1006.3</td>\n      <td>1004.4</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>26.6</td>\n      <td>33.4</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>6050</th>\n      <td>2009-01-02</td>\n      <td>Cobar</td>\n      <td>18.4</td>\n      <td>28.9</td>\n      <td>0.0</td>\n      <td>14.8</td>\n      <td>13.0</td>\n      <td>S</td>\n      <td>37.0</td>\n      <td>SSE</td>\n      <td>...</td>\n      <td>30.0</td>\n      <td>8.0</td>\n      <td>1012.9</td>\n      <td>1012.1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>20.3</td>\n      <td>27.0</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>6051</th>\n      <td>2009-01-03</td>\n      <td>Cobar</td>\n      <td>15.5</td>\n      <td>34.1</td>\n      <td>0.0</td>\n      <td>12.6</td>\n      <td>13.3</td>\n      <td>SE</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>1011.6</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>32.7</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>6052</th>\n      <td>2009-01-04</td>\n      <td>Cobar</td>\n      <td>19.4</td>\n      <td>37.6</td>\n      <td>0.0</td>\n      <td>10.8</td>\n      <td>10.6</td>\n      <td>NNE</td>\n      <td>46.0</td>\n      <td>NNE</td>\n      <td>...</td>\n      <td>42.0</td>\n      <td>22.0</td>\n      <td>1012.3</td>\n      <td>1009.2</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>28.7</td>\n      <td>34.9</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>6053</th>\n      <td>2009-01-05</td>\n      <td>Cobar</td>\n      <td>21.9</td>\n      <td>38.4</td>\n      <td>0.0</td>\n      <td>11.4</td>\n      <td>12.2</td>\n      <td>WNW</td>\n      <td>31.0</td>\n      <td>WNW</td>\n      <td>...</td>\n      <td>37.0</td>\n      <td>22.0</td>\n      <td>1012.7</td>\n      <td>1009.1</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>29.1</td>\n      <td>35.6</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>142298</th>\n      <td>2017-06-20</td>\n      <td>Darwin</td>\n      <td>19.3</td>\n      <td>33.4</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>11.0</td>\n      <td>ENE</td>\n      <td>35.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>63.0</td>\n      <td>32.0</td>\n      <td>1013.9</td>\n      <td>1010.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>24.5</td>\n      <td>32.3</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>142299</th>\n      <td>2017-06-21</td>\n      <td>Darwin</td>\n      <td>21.2</td>\n      <td>32.6</td>\n      <td>0.0</td>\n      <td>7.6</td>\n      <td>8.6</td>\n      <td>E</td>\n      <td>37.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>56.0</td>\n      <td>28.0</td>\n      <td>1014.6</td>\n      <td>1011.2</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>24.8</td>\n      <td>32.0</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>142300</th>\n      <td>2017-06-22</td>\n      <td>Darwin</td>\n      <td>20.7</td>\n      <td>32.8</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>11.0</td>\n      <td>E</td>\n      <td>33.0</td>\n      <td>E</td>\n      <td>...</td>\n      <td>46.0</td>\n      <td>23.0</td>\n      <td>1015.3</td>\n      <td>1011.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>24.8</td>\n      <td>32.1</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>142301</th>\n      <td>2017-06-23</td>\n      <td>Darwin</td>\n      <td>19.5</td>\n      <td>31.8</td>\n      <td>0.0</td>\n      <td>6.2</td>\n      <td>10.6</td>\n      <td>ESE</td>\n      <td>26.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>58.0</td>\n      <td>1014.9</td>\n      <td>1010.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>24.8</td>\n      <td>29.2</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>142302</th>\n      <td>2017-06-24</td>\n      <td>Darwin</td>\n      <td>20.2</td>\n      <td>31.7</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>10.7</td>\n      <td>ENE</td>\n      <td>30.0</td>\n      <td>ENE</td>\n      <td>...</td>\n      <td>73.0</td>\n      <td>32.0</td>\n      <td>1013.9</td>\n      <td>1009.7</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>25.4</td>\n      <td>31.0</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>75625 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\nWe haven't stored this transformation, because filtering nulls without careful consideration is a bad idea, but it's useful to know, nonetheless.\n\nThere are lots of ways we could transform the data, but the final example we will consider here is reshaping the data using `pd.DataFrame.pivot()`, which transforms the data from long to wide format data, and `pd.DataFrame.melt()`, which transforms it from wide to long format.\n\nPerhaps we want to focus on the maximum temperature per day in each location in 2015. We can use `pd.Series.dt.year` to get the year from the date column, and filter for the year 2015, before reshaping the data.\n\n::: {#cell-pivot .cell execution_count=35}\n``` {.python .cell-code}\ndf2015 = df.loc[df['Date'].dt.year == 2015]\ndf_wide = df2015.pivot(index='Date', columns='Location', values='MaxTemp')\n\ndf_wide.head()\n```\n\n::: {#pivot .cell-output .cell-output-display execution_count=35}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Location</th>\n      <th>Adelaide</th>\n      <th>Albany</th>\n      <th>Albury</th>\n      <th>AliceSprings</th>\n      <th>BadgerysCreek</th>\n      <th>Ballarat</th>\n      <th>Bendigo</th>\n      <th>Brisbane</th>\n      <th>Cairns</th>\n      <th>Canberra</th>\n      <th>...</th>\n      <th>Townsville</th>\n      <th>Tuggeranong</th>\n      <th>Uluru</th>\n      <th>WaggaWagga</th>\n      <th>Walpole</th>\n      <th>Watsonia</th>\n      <th>Williamtown</th>\n      <th>Witchcliffe</th>\n      <th>Wollongong</th>\n      <th>Woomera</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-01</th>\n      <td>37.0</td>\n      <td>21.9</td>\n      <td>33.5</td>\n      <td>40.3</td>\n      <td>34.7</td>\n      <td>27.4</td>\n      <td>31.2</td>\n      <td>31.3</td>\n      <td>33.7</td>\n      <td>32.6</td>\n      <td>...</td>\n      <td>32.6</td>\n      <td>32.1</td>\n      <td>42.0</td>\n      <td>35.2</td>\n      <td>23.6</td>\n      <td>28.3</td>\n      <td>33.7</td>\n      <td>25.0</td>\n      <td>25.3</td>\n      <td>39.2</td>\n    </tr>\n    <tr>\n      <th>2015-01-02</th>\n      <td>44.1</td>\n      <td>21.2</td>\n      <td>39.6</td>\n      <td>41.4</td>\n      <td>30.5</td>\n      <td>38.2</td>\n      <td>39.8</td>\n      <td>30.5</td>\n      <td>33.7</td>\n      <td>35.2</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>34.1</td>\n      <td>42.4</td>\n      <td>38.9</td>\n      <td>21.1</td>\n      <td>40.6</td>\n      <td>29.3</td>\n      <td>23.6</td>\n      <td>24.6</td>\n      <td>43.3</td>\n    </tr>\n    <tr>\n      <th>2015-01-03</th>\n      <td>38.2</td>\n      <td>21.5</td>\n      <td>38.3</td>\n      <td>36.4</td>\n      <td>34.3</td>\n      <td>37.5</td>\n      <td>40.3</td>\n      <td>28.9</td>\n      <td>33.6</td>\n      <td>34.7</td>\n      <td>...</td>\n      <td>28.1</td>\n      <td>33.7</td>\n      <td>39.8</td>\n      <td>37.5</td>\n      <td>21.8</td>\n      <td>39.5</td>\n      <td>32.8</td>\n      <td>23.0</td>\n      <td>25.7</td>\n      <td>44.7</td>\n    </tr>\n    <tr>\n      <th>2015-01-04</th>\n      <td>30.5</td>\n      <td>23.3</td>\n      <td>33.1</td>\n      <td>29.0</td>\n      <td>34.8</td>\n      <td>23.5</td>\n      <td>29.0</td>\n      <td>30.2</td>\n      <td>29.4</td>\n      <td>32.5</td>\n      <td>...</td>\n      <td>31.6</td>\n      <td>32.8</td>\n      <td>36.1</td>\n      <td>33.8</td>\n      <td>24.4</td>\n      <td>25.1</td>\n      <td>34.5</td>\n      <td>29.8</td>\n      <td>25.3</td>\n      <td>37.6</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>34.9</td>\n      <td>24.9</td>\n      <td>35.2</td>\n      <td>27.1</td>\n      <td>27.2</td>\n      <td>26.6</td>\n      <td>33.6</td>\n      <td>28.1</td>\n      <td>31.4</td>\n      <td>29.6</td>\n      <td>...</td>\n      <td>31.6</td>\n      <td>28.9</td>\n      <td>38.8</td>\n      <td>34.9</td>\n      <td>29.5</td>\n      <td>25.7</td>\n      <td>27.0</td>\n      <td>31.7</td>\n      <td>23.1</td>\n      <td>38.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 49 columns</p>\n</div>\n```\n:::\n:::\n\n\nPerhaps we want to look at the maximum and minimum temperatures in each location, together. We can reshape the data to support this[^Viz].\n\n::: {#cell-melt .cell execution_count=36}\n``` {.python .cell-code}\ndf_long = df2015.melt(\n    id_vars=['Date', 'Location'],\n    value_vars=['MaxTemp', 'MinTemp'],\n    var_name='Variable',\n    value_name='Value'\n)\n\ndf_long.head()\n```\n\n::: {#melt .cell-output .cell-output-display execution_count=36}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>Variable</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-01-01</td>\n      <td>Albury</td>\n      <td>MaxTemp</td>\n      <td>33.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-01-02</td>\n      <td>Albury</td>\n      <td>MaxTemp</td>\n      <td>39.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-01-03</td>\n      <td>Albury</td>\n      <td>MaxTemp</td>\n      <td>38.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-01-04</td>\n      <td>Albury</td>\n      <td>MaxTemp</td>\n      <td>33.1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-01-05</td>\n      <td>Albury</td>\n      <td>MaxTemp</td>\n      <td>35.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n[^Viz]:\n\nThis is often very useful when we need to visualise data, for example plotting the max and min temp for each location, is easier if the values are organised in the same column and differentiated using another column.\n\n## Exercises\n\nSome of these questions are easily answered by scrolling up and finding the answer in the output of the above code, however, the goal is to find the answer using code. No one actually cares what the answer to any of these questions is, it's the process that matters!\n\n**Remember, if you don't know the answer, it's okay to Google it (or speak to others, including me, for help)!**\n\n::: {#reset-data .cell execution_count=37}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Import Data (to Reset)\"}\n# import the dataset\ndf = pd.read_csv('data/weatherAUS.csv')\n```\n:::\n\n\n1. What is the 'Sunshine' column's data type?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#col-type .cell execution_count=38}\n``` {.python .cell-code}\n# What is the 'Sunshine' column's data type?\nprint(df['Sunshine'].dtypes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfloat64\n```\n:::\n:::\n\n\n:::\n\n2. Identify all the columns that are of dtype 'object'.\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#object-cols .cell execution_count=39}\n``` {.python .cell-code}\n# Identify all the columns that are of dtype 'object'\nprint(list(df.select_dtypes(include=['object'])))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n```\n:::\n:::\n\n\n:::\n\n3. How many of the dataframe's columns are of dtype 'object'?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#cell-count-object-cols .cell execution_count=40}\n``` {.python .cell-code}\n# How many of the dataframe's columns are of dtype 'object'?\nlen(list(df.select_dtypes(include=['object'])))\n```\n\n::: {#count-object-cols .cell-output .cell-output-display execution_count=40}\n```\n7\n```\n:::\n:::\n\n\n:::\n\n4. How many of the 'Rainfall' column values are NAs?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#count-rainfall-nulls .cell execution_count=41}\n``` {.python .cell-code}\n# How many of the 'Rainfall' column values are NAs?\nprint(df['Rainfall'].isna().sum())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3261\n```\n:::\n:::\n\n\n:::\n\n5. Create a new dataframe which only includes the 'Date', 'Location, 'Sunshine', 'Rainfall', and 'RainTomorrow' columns.\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#cell-subset-data .cell execution_count=42}\n``` {.python .cell-code}\nnew_df = df[['Date', 'Location', 'Sunshine', 'Rainfall', 'RainTomorrow']]\nnew_df.head()\n```\n\n::: {#subset-data .cell-output .cell-output-display execution_count=42}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>Sunshine</th>\n      <th>Rainfall</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-12-01</td>\n      <td>Albury</td>\n      <td>NaN</td>\n      <td>0.6</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-12-02</td>\n      <td>Albury</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-12-03</td>\n      <td>Albury</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-12-04</td>\n      <td>Albury</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-12-05</td>\n      <td>Albury</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n\n6. Convert 'RainTomorrow' to a numeric variable, where 'Yes' = 1 and 'No' = 0.\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#cell-numeric-outcome .cell execution_count=43}\n``` {.python .cell-code}\n# df['Location'].astype('category').cat.codes\n# df['RainTomorrow'].astype('category').cat.codes\ndf['RainTomorrow'].map({'Yes': 1, 'No': 0})\n```\n\n::: {#numeric-outcome .cell-output .cell-output-display execution_count=43}\n```\n0         0.0\n1         0.0\n2         0.0\n3         0.0\n4         0.0\n         ... \n145455    0.0\n145456    0.0\n145457    0.0\n145458    0.0\n145459    NaN\nName: RainTomorrow, Length: 145460, dtype: float64\n```\n:::\n:::\n\n\n:::\n\n7. What is the average amount of rainfall for each location?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#cell-avg-rainfall-location .cell execution_count=44}\n``` {.python .cell-code}\n# average rainfall by location, sorted by value\ndf.groupby('Location')['Rainfall'].mean().sort_values(ascending=False)\n```\n\n::: {#avg-rainfall-location .cell-output .cell-output-display execution_count=44}\n```\nLocation\nCairns              5.742035\nDarwin              5.092452\nCoffsHarbour        5.061497\nGoldCoast           3.769396\nWollongong          3.594903\nWilliamtown         3.591108\nTownsville          3.485592\nNorahHead           3.387299\nSydney              3.324543\nMountGinini         3.292260\nKatherine           3.201090\nNewcastle           3.183892\nBrisbane            3.144891\nNorfolkIsland       3.127665\nSydneyAirport       3.009917\nWalpole             2.906846\nWitchcliffe         2.895664\nPortland            2.530374\nAlbany              2.263859\nBadgerysCreek       2.193101\nPenrith             2.175304\nTuggeranong         2.164043\nDartmoor            2.146567\nRichmond            2.138462\nMountGambier        2.087562\nLaunceston          2.011988\nAlbury              1.914115\nPerth               1.906295\nMelbourne           1.870062\nWatsonia            1.860820\nPerthAirport        1.761648\nCanberra            1.741720\nBallarat            1.740026\nWaggaWagga          1.709946\nPearceRAAF          1.669080\nMoree               1.630203\nBendigo             1.619380\nHobart              1.601819\nAdelaide            1.566354\nSale                1.510167\nMelbourneAirport    1.451977\nNuriootpa           1.390343\nCobar               1.127309\nSalmonGums          1.034382\nMildura             0.945062\nNhil                0.934863\nAliceSprings        0.882850\nUluru               0.784363\nWoomera             0.490405\nName: Rainfall, dtype: float64\n```\n:::\n:::\n\n\n:::\n\n8. What is the average amount of rainfall for days that it will rain tomorrow?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#cell-avg-rainfall-rain-tomorrow .cell execution_count=45}\n``` {.python .cell-code}\n# average rainfall depending on whether it will rain tomorrow or not\ndf.groupby('RainTomorrow')['Rainfall'].mean()\n```\n\n::: {#avg-rainfall-rain-tomorrow .cell-output .cell-output-display execution_count=45}\n```\nRainTomorrow\nNo     1.270290\nYes    6.142104\nName: Rainfall, dtype: float64\n```\n:::\n:::\n\n\n:::\n\n9. What is the average amount of sunshine in Perth when it will not rain tomorrow?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#cell-avg-sunshine-perth-no-rain .cell execution_count=46}\n``` {.python .cell-code}\n# average sunshine in Perth when it won't rain tomorrow\ndf.loc[(df['Location'] == 'Perth') & (df['RainTomorrow'] == 'No'), 'Sunshine'].mean()\n# df[(df['Location']=='Perth') & (df['RainTomorrow']=='No')]['Sunshine'].mean()\n```\n\n::: {#avg-sunshine-perth-no-rain .cell-output .cell-output-display execution_count=46}\n```\nnp.float64(9.705306603773584)\n```\n:::\n:::\n\n\n:::\n\n10. We want to understand the role that time plays in the dataset. Using the original dataframe, carry the following tasks and answer the corresponding questions:\n    - Create columns representing the year and month from the 'Date' column. How many years of data are in the dataset?\n    - Examine the distribution of the 'Sunshine' NAs over time. Is time a component in the 'Sunshine' data quality issues?\n    - Calculate the average rainfall and sunshine by month. How do rainfall and sunshine vary through the year?\n    - Calculate the average rainfall and sunshine by year. How have rainfall and sunshine changed over time?\n\n::: {.callout-note title=\"Solution\" collapse=\"true\"}\n\n::: {#cell-unique-years .cell execution_count=47}\n``` {.python .cell-code}\n# get year and month columns\ndf = (\n    df.assign(Date=pd.to_datetime(df['Date']))\n    .assign(\n        Year=lambda x: x['Date'].dt.year,\n        Month=lambda x: x['Date'].dt.month\n    )\n)\n\n# count unique years\ndf['Year'].nunique()\n```\n\n::: {#unique-years .cell-output .cell-output-display execution_count=47}\n```\n11\n```\n:::\n:::\n\n\n::: {#cell-sunshine-nulls-over-time .cell execution_count=48}\n``` {.python .cell-code}\n# lambda function counting nulls by year\ndf.groupby('Year')['Sunshine'].apply(lambda x: x.isna().sum())\n```\n\n::: {#sunshine-nulls-over-time .cell-output .cell-output-display execution_count=48}\n```\nYear\n2007        0\n2008      323\n2009     6146\n2010     6220\n2011     6053\n2012     6539\n2013     7570\n2014     9157\n2015     9441\n2016    11994\n2017     6392\nName: Sunshine, dtype: int64\n```\n:::\n:::\n\n\n::: {#cell-rainfall-sunshine-by-month .cell execution_count=49}\n``` {.python .cell-code}\n# rainfall and sunshine by month\ndf.groupby('Month')[['Rainfall', 'Sunshine']].mean().round(1)\n```\n\n::: {#rainfall-sunshine-by-month .cell-output .cell-output-display execution_count=49}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rainfall</th>\n      <th>Sunshine</th>\n    </tr>\n    <tr>\n      <th>Month</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2.7</td>\n      <td>9.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.2</td>\n      <td>8.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.8</td>\n      <td>7.6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.3</td>\n      <td>7.1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.0</td>\n      <td>6.3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2.8</td>\n      <td>5.6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.2</td>\n      <td>6.1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2.0</td>\n      <td>7.1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.9</td>\n      <td>7.7</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.6</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2.3</td>\n      <td>8.7</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2.5</td>\n      <td>9.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#cell-rainfall-sunshine-by-year .cell execution_count=50}\n``` {.python .cell-code}\n# rainfall and sunshine by year\ndf.groupby('Year')[['Rainfall', 'Sunshine']].mean().round(1)\n```\n\n::: {#rainfall-sunshine-by-year .cell-output .cell-output-display execution_count=50}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rainfall</th>\n      <th>Sunshine</th>\n    </tr>\n    <tr>\n      <th>Year</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2007</th>\n      <td>3.2</td>\n      <td>8.1</td>\n    </tr>\n    <tr>\n      <th>2008</th>\n      <td>2.3</td>\n      <td>7.8</td>\n    </tr>\n    <tr>\n      <th>2009</th>\n      <td>2.2</td>\n      <td>7.9</td>\n    </tr>\n    <tr>\n      <th>2010</th>\n      <td>2.7</td>\n      <td>7.3</td>\n    </tr>\n    <tr>\n      <th>2011</th>\n      <td>2.8</td>\n      <td>7.3</td>\n    </tr>\n    <tr>\n      <th>2012</th>\n      <td>2.4</td>\n      <td>7.6</td>\n    </tr>\n    <tr>\n      <th>2013</th>\n      <td>2.3</td>\n      <td>7.7</td>\n    </tr>\n    <tr>\n      <th>2014</th>\n      <td>2.0</td>\n      <td>7.8</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>2.2</td>\n      <td>7.7</td>\n    </tr>\n    <tr>\n      <th>2016</th>\n      <td>2.4</td>\n      <td>7.6</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>2.5</td>\n      <td>7.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}